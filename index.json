
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":["胡传鹏"],"categories":null,"content":"Dr. Hu Chuan-Peng is currently a faculty member of the School of Psychology, Nanjing Normal University. In 2017, Chuan-Peng received his PhD degree in Psychology at the Department of Psychology, Tsinghua University, Beijing, china. After that, he worked as a post-doc at the Leibniz Institute for Resilience Research (LIR). He started his journey in open science and metas-cienceafter two failed replications of published papers during his master and PhD training. He became an ambassador of the Center for Open Science since 2016. Now, Chuan-Peng’s research interests include self-cognition, metascience, and Bayesian modelling.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"feee344ee7997eedf2d4fb0121544b3a","permalink":"https://terryzang.github.io/author/chuan-peng-hu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chuan-peng-hu/","section":"authors","summary":"Dr. Hu Chuan-Peng is currently a faculty member of the School of Psychology, Nanjing Normal University. In 2017, Chuan-Peng received his PhD degree in Psychology at the Department of Psychology, Tsinghua University, Beijing, china. After that, he worked as a post-doc at the Leibniz Institute for Resilience Research (LIR). He started his journey in open science and metas-cienceafter two failed replications of published papers during his master and PhD training. He became an ambassador of the Center for Open Science since 2016. Now, Chuan-Peng’s research interests include self-cognition, metascience, and Bayesian modelling.\n","tags":null,"title":"Chuan-Peng Hu","type":"authors"},{"authors":["耿海洋"],"categories":null,"content":"Dr. Haiyang Geng is a postdoc researcher in Dr. Xiaoging Hu’s lab at The University of Hong KongHis current research focuses on memory, decision and psychopathology (i.e. anxiety, depressionand schizophrenia) by using computational modeling and advanced neuroimaging approaches. in2012, Haiyang Geng obtained his bachelor degree in bioinformatics at Harbin Medical University.After that, tremendous interest and curiosity drive him to enter the field of cognitive neuroscienceDuring his master, he worked with Dr. Xuebing Li in the Institute of Psychology, Chinese Academy ofScience on the topic of exploring neural mechanisms of anxiety. in 2015, he got his master degreein cognitive neuroscience. During 2015-2016, he worked with Dr. Shaozheng Qin at Beijing NormalUniversity on modulation of stress, anxiety on working memory. During 2016-2020, he joined thePh.D. program at the University of Groningen. During his Ph.D., Haiyang was supervised by prof.Andre Aleman and prof, Yue-Jia Luo, His Ph.D, research is to examine how disrupted predictionprocesses may contribute to a variety of psychiatric symptoms (i.e. anxiety, hallucination andapathy) by using multiple neuroimaging approaches including brain activation, connectivity (i.e.psychophysiological interaction (PPl)) and dynamic functional connectivity (i.e. sliding window, Kmeans and phase synchronization), graph theory (i.e. modularity analysis).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e2b66897d4e560faef4f42be7502ab1f","permalink":"https://terryzang.github.io/author/haiyang-geng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/haiyang-geng/","section":"authors","summary":"Dr. Haiyang Geng is a postdoc researcher in Dr. Xiaoging Hu’s lab at The University of Hong KongHis current research focuses on memory, decision and psychopathology (i.e. anxiety, depressionand schizophrenia) by using computational modeling and advanced neuroimaging approaches. in2012, Haiyang Geng obtained his bachelor degree in bioinformatics at Harbin Medical University.After that, tremendous interest and curiosity drive him to enter the field of cognitive neuroscienceDuring his master, he worked with Dr. Xuebing Li in the Institute of Psychology, Chinese Academy ofScience on the topic of exploring neural mechanisms of anxiety. in 2015, he got his master degreein cognitive neuroscience. During 2015-2016, he worked with Dr. Shaozheng Qin at Beijing NormalUniversity on modulation of stress, anxiety on working memory. During 2016-2020, he joined thePh.D. program at the University of Groningen. During his Ph.D., Haiyang was supervised by prof.Andre Aleman and prof, Yue-Jia Luo, His Ph.D, research is to examine how disrupted predictionprocesses may contribute to a variety of psychiatric symptoms (i.e. anxiety, hallucination andapathy) by using multiple neuroimaging approaches including brain activation, connectivity (i.e.psychophysiological interaction (PPl)) and dynamic functional connectivity (i.e. sliding window, Kmeans and phase synchronization), graph theory (i.e. modularity analysis).\n","tags":null,"title":"Haiyang Geng","type":"authors"},{"authors":["金海洋"],"categories":null,"content":"Dr. Haiyang Jin is a postdoctoraassociate in Dr. Olivia Cheung’s lab atthe New York University Abu Dhabi. Heobtained his Ph.D. in psychology at theUniversity of Auckland, New Zealandunder the supervision of Prof. WilliamG. Hayward, Assoc/Prof. Paul M.Corballis, and Assoc/Prof. SamSchwarzkopf. He is interested inunderstanding face perception, holisticface processing, and vision sciencesusing psychophysics, EEG/ERP, fMRIand eye-tracking. He is also a big fanof statistics, e.g., (generalized) linearmixed-effects modeling, Bayesianhierarchical modeling, and the “newstatistics”.Personal website.https://haiyangjin.github.io/.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7676acd3ca09f08fc241d162674bae47","permalink":"https://terryzang.github.io/author/haiyang-jin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/haiyang-jin/","section":"authors","summary":"Dr. Haiyang Jin is a postdoctoraassociate in Dr. Olivia Cheung’s lab atthe New York University Abu Dhabi. Heobtained his Ph.D. in psychology at theUniversity of Auckland, New Zealandunder the supervision of Prof. WilliamG. Hayward, Assoc/Prof. Paul M.Corballis, and Assoc/Prof. SamSchwarzkopf. He is interested inunderstanding face perception, holisticface processing, and vision sciencesusing psychophysics, EEG/ERP, fMRIand eye-tracking. He is also a big fanof statistics, e.g., (generalized) linearmixed-effects modeling, Bayesianhierarchical modeling, and the “newstatistics”.Personal website.https://haiyangjin.github.io/.\n","tags":null,"title":"Haiyang Jin","type":"authors"},{"authors":["张磊"],"categories":null,"content":"Dr. Zhang is XXX.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e315f790fb49b7d221e2403469652f58","permalink":"https://terryzang.github.io/author/lei-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/lei-zhang/","section":"authors","summary":"Dr. Zhang is XXX.\n","tags":null,"title":"Lei Zhang","type":"authors"},{"authors":["高梦宇"],"categories":null,"content":"Dr Mengyu Gao is an Assistant Professor in Developmental Psychology at Beijing Normal University, China. Dr Gao obtained herPhD in Developmental Paychology anda minor in Quantitative Psychology atthe University of Notre Dame in 2019.She pursued a postdoctoral training atthe University of Utah fomr 2019-2021. Dr. Gao studies how the perinatal environment and family relationships confer risk and resilience for the development of psychopathology, with a particular focus on child emotion regulation. Shefuels herself by outdoor activities, board games, cooking, and companiesof her family.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ad71aa7a9729b89e7ba9f1b147a802a0","permalink":"https://terryzang.github.io/author/mengyu-gao-miranda/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mengyu-gao-miranda/","section":"authors","summary":"Dr Mengyu Gao is an Assistant Professor in Developmental Psychology at Beijing Normal University, China. Dr Gao obtained herPhD in Developmental Paychology anda minor in Quantitative Psychology atthe University of Notre Dame in 2019.She pursued a postdoctoral training atthe University of Utah fomr 2019-2021. Dr. Gao studies how the perinatal environment and family relationships confer risk and resilience for the development of psychopathology, with a particular focus on child emotion regulation. Shefuels herself by outdoor activities, board games, cooking, and companiesof her family.\n","tags":null,"title":"Mengyu Gao (Miranda)","type":"authors"},{"authors":["刘泉影"],"categories":null,"content":"Dr. Quanying Liu is an assistantprofessor at SUSTech, ShenzhenChina, Pl of Neural Computing andControl lab. Her research interests arehighly interdisciplinary, including multi-modal neuroimaging, brain networkmodeling, neurocomputational modelling, Al and neurofeedback control.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ec27b7eebf8ad097d1ed42fda22bf6d2","permalink":"https://terryzang.github.io/author/quanying-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/quanying-liu/","section":"authors","summary":"Dr. Quanying Liu is an assistantprofessor at SUSTech, ShenzhenChina, Pl of Neural Computing andControl lab. Her research interests arehighly interdisciplinary, including multi-modal neuroimaging, brain networkmodeling, neurocomputational modelling, Al and neurofeedback control.\n","tags":null,"title":"Quanying Liu","type":"authors"},{"authors":["张融"],"categories":null,"content":"Zhang Rong is currently pursuing a doctoral degree at the School of Psychology of South China Normal University.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"07443fd5d44191036bcfc53ac574cb36","permalink":"https://terryzang.github.io/author/rong-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/rong-zhang/","section":"authors","summary":"Zhang Rong is currently pursuing a doctoral degree at the School of Psychology of South China Normal University.\n","tags":null,"title":"Rong Zhang","type":"authors"},{"authors":["张洳源"],"categories":null,"content":"Dr. Zhang Ruoyuan is currently the dual-appointed project leader of the School of Psychology at Shanghai Jiao Tong University and the Mental Health Center Affiliated to Shanghai Jiao Tong University School of Medicine. He leads the Cognitive Computational Neuroscience and Brain Imaging research group. Zhang Ruoyuan graduated from the School of Psychology and Cognitive Science at Peking University with a bachelor’s degree, and obtained his doctorate from the Department of Brain and Cognitive Science at the University of Rochester. After that, he conducted postdoctoral research at the University of Minnesota and the National Institutes of Health in the United States. Zhang Ruoyuan has been dedicated to interdisciplinary research at the intersection of brain science and artificial intelligence, integrating research methods such as psychophysics, Bayesian probability models, deep learning models, neural regulation, and nuclear magnetic resonance to explore the neural computing mechanisms of the human brain and artificial intelligence.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"47e531748b768351c28ef361e515d53e","permalink":"https://terryzang.github.io/author/ruyuan-zhang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ruyuan-zhang/","section":"authors","summary":"Dr. Zhang Ruoyuan is currently the dual-appointed project leader of the School of Psychology at Shanghai Jiao Tong University and the Mental Health Center Affiliated to Shanghai Jiao Tong University School of Medicine. He leads the Cognitive Computational Neuroscience and Brain Imaging research group. Zhang Ruoyuan graduated from the School of Psychology and Cognitive Science at Peking University with a bachelor’s degree, and obtained his doctorate from the Department of Brain and Cognitive Science at the University of Rochester. After that, he conducted postdoctoral research at the University of Minnesota and the National Institutes of Health in the United States. Zhang Ruoyuan has been dedicated to interdisciplinary research at the intersection of brain science and artificial intelligence, integrating research methods such as psychophysics, Bayesian probability models, deep learning models, neural regulation, and nuclear magnetic resonance to explore the neural computing mechanisms of the human brain and artificial intelligence.\n","tags":null,"title":"Ruyuan Zhang","type":"authors"},{"authors":["王鑫迪"],"categories":null,"content":"Dr. Xindi Wang is now a senio!algorithm engineer at Beijing Intelligent Brain Cloud, Inc., Beijing China. He is a code contributor and maintainer Of GRETNA, REST, DPAB!and contributor of ClVET. During 2011-2018, he was supervised by ProfYufeng Zang and Prof. Yong He in theNational Key Laboratory of Cognitive Neuroscience and Learning at Beijing Normal University and tried to explored if ferentiated hubs in structural human networks. After obtaining his PhDdegree, he move to Montreal Neurological Institute (MNl) and work with Prof. Alan C Evans.In 2021, He joined Beijing Intelligent Brain CloudInc.and continue to contribute onbrain MR imaging methodology. Hiscurrent research focuses on the qualitycontrol of multi-modal MRl from multisite. He is also interested in improvingMR imaging preprocessing by usingdeep learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"940b787481ebf1b799344d9ca57bbf55","permalink":"https://terryzang.github.io/author/wang-xindi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/wang-xindi/","section":"authors","summary":"Dr. Xindi Wang is now a senio!algorithm engineer at Beijing Intelligent Brain Cloud, Inc., Beijing China. He is a code contributor and maintainer Of GRETNA, REST, DPAB!and contributor of ClVET. During 2011-2018, he was supervised by ProfYufeng Zang and Prof. Yong He in theNational Key Laboratory of Cognitive Neuroscience and Learning at Beijing Normal University and tried to explored if ferentiated hubs in structural human networks. After obtaining his PhDdegree, he move to Montreal Neurological Institute (MNl) and work with Prof. Alan C Evans.In 2021, He joined Beijing Intelligent Brain CloudInc.and continue to contribute onbrain MR imaging methodology. Hiscurrent research focuses on the qualitycontrol of multi-modal MRl from multisite. He is also interested in improvingMR imaging preprocessing by usingdeep learning.\n","tags":null,"title":"Wang Xindi","type":"authors"},{"authors":["臧鑫磊"],"categories":null,"content":"I am dedicated to advancing and reshaping the theories within psychological science through the lens of the philosophy of science. My recent work focuses on cutting-edge interdisciplinary research, primarily involving machine learning and pattern recognition, signal processing and feature engineering, computational modeling of cognition and behavior, and the philosophy of science as it applies to psychology (reflecting on both theory and technology).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0f69b50547d62d7608075ea63af403f9","permalink":"https://terryzang.github.io/author/xinlei-zang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xinlei-zang/","section":"authors","summary":"I am dedicated to advancing and reshaping the theories within psychological science through the lens of the philosophy of science. My recent work focuses on cutting-edge interdisciplinary research, primarily involving machine learning and pattern recognition, signal processing and feature engineering, computational modeling of cognition and behavior, and the philosophy of science as it applies to psychology (reflecting on both theory and technology).\n","tags":null,"title":"Xinlei Zang","type":"authors"},{"authors":["OpenTalks Team"],"categories":null,"content":"分享嘉宾:\n刘泉影，南方科技大学长聘副教授，博导，PI。2010年/2013年毕业于兰州大学信息学院，获学士/硕士学位。2017年于瑞士苏黎世联邦理工学院获博士学位，其后在美国加州理工学院从事博士后研究工作。2019年8月回国，在南方科技大学成立神经计算与控制实验室（NCC lab）。主要研究方向是多模态神经信号处理算法、脑网络动力学建模、神经编解码算法、神经调控优化算法等工作，致力于从人工智能、控制理论和脑科学交叉融合的视角，发展基于AI的多模态神经解码算法，构建数据驱动的AI孪生脑模型，研发智能化的闭环神经调控系统，推动“读出-写入”双向脑机接口技术的发展，为解码脑功能和干预神经疾病提供全新范式，已在Nature Methods、The Innovation等期刊，NeurIPS、ICML、ICLR等机器学习顶会上发表论文60余篇。 ","date":1757797200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1757797200,"objectID":"277f76009c27da8198e0fc7b8d768114","permalink":"https://terryzang.github.io/event/opentalk/2025_89/","publishdate":"2025-06-05T00:00:00Z","relpermalink":"/event/opentalk/2025_89/","section":"event","summary":"AI孪生脑：模型训练、评估、应用。","tags":["OT"],"title":"OpenTalks #89 | AI孪生脑：模型训练、评估、应用","type":"event"},{"authors":["COSN Team"],"categories":null,"content":"COSN Summer Hackathon又双叒来啦！！！通过2022年 ～ 2024年的三次活动，越来越多的小伙伴有机会参与了Hackathon。今年的Hackathon将以“AI + 脑科学”为主题，聚焦人工智能技术在脑科学领域的探索与应用，欢迎大家提出相关的Project（提交的具体流程之后会公布）！\n“Learning by doing” 或者在实践中学习是Hackathon 的精神，本次Hackathon将为您提供：\n与神经科学、认知科学和人工智能领域学者的交流机会； 与神经科学领域资深编程大神交流，推动自己研究项目的机会； 与志同道合的小伙伴建立联系探索未来合作的机会； 探索AI与脑科学结合的无限可能； 了解开放科学和可重复研究的机会等等 你可能会问，什么是hackathon？是暑期学校吗？\n什么是Hackathon？\nHackathon，也叫Hacking Day、Hackfest, Datathon 或者Codefest，是Hacking和Marathon的结合。最初是由一些编程人员聚在一起，针对某些特定主题集中1-2天进行的高强度的编程开发活动。随后，这种活动的组织方式也扩展到了其他领域。生命科学、神经、行为和心理科学相关领域都有20余年的Hackathon传统，生物信息学和神经信息学的学者们在领导和组织hackathon方面发挥了重要作用，hackathon通过促进学生和学者的沟通和讨论，产生了非常多有意义和价值的项目，并且促成了日后的长期合作。 近些年，随着开放科学（Open Science）被学术界广泛认可，开放科学兴趣小组（Open Science Special Interest Group）在Hackathon活动的组织和参与上也非常活跃。更加严谨的方法和更加先进和可靠的信息平台支持是开放科学不可或缺的基础。参考Brainhack和OHBM, hackathon的内容一般包含两个部分：1）TrainTrack：以报告为主要形式，分享主题内容或者教程；2）HackTrack：以项目为导向的自由组队讨论和编程开发，在hackathon结束时分享本次hack的体验和收获，项目可以在Hackthon结束之后长期保持合作。 Hackathon并不是一般意义上的暑期学校或者工作坊、培训，而是更需要于深度参与和合作的“做中学”。具体而言有如下几个特点： 问题解决导向。Hackathon中，一群人为了解决某一个问题而创造共同的时空情境，大家主要通过写代码（hack）来解决问题；问题既可以是一个大的研究，也可以是一个研究中的技术挑战。\n深度参与。正是由于hackathon是为了解决问题，因此参与其中的个体需要更加深度的参与，仅仅倾听可能是不太够的；\n扁平化结构。Hackathon虽然有TrainTrack，面向初级的hacker，其特色更在于Hack，即通过coding解决问题，因此没有传统工作坊和暑期校中“教员－学员”的结构，而是更多的平等合作与探索，大家各自发挥优势，一起解决问题。\n谁适合本次Hackathon？\n本Hackathon适合各个职业发展阶段的研究者，如果您符合如下特点，非常欢迎您参加(由于人手有限，我们或限制最终参加人数)：\n希望了解认知神经科学、脑科学及编程应用；\n渴望学习新知识，增加编程相关的实践经验；\n可以保证两天全身心的投入到Hackathon中（特殊情况除外）\n本次Hackathon的安排\n时间：2025年08月23日、24日（周六、周日） 线下地址：深圳 线上联动：使用腾讯会议进行即时通讯 会议费用：会议免费（含两日午餐和茶歇），交通和住宿自理\n主题圆桌讨论：“思想钢印”技术离现实有多远？\n本年度的COSN Hackathon 活动获得三体宇宙公司支持，开启脑科学与三体的特别主题圆桌讨论。围绕科幻小说《三体》中提出的“思想钢印”概念，汇聚来自心理学、神经科学、脑机接口等领域的专家学者，将进行跨学科深度对话。 本场 Panel 可能涉及到的关键脑科学前沿议题： 记忆操控与干预的科学可能性\n非侵入与侵入式神经调控方法\n脑机接口（BCI）的增强与应用前景\n意识与无意识通路的完整解析\n神经信息的编码与解码技术进展\n人脑如何进行道德两难决策\n讨论嘉宾：完整名单将在第二轮通知中公布\n活动形式：一小时跨界深度对话 \u0026amp; 三十分钟观众互动提问（Q\u0026amp;A）\n这将是一场融合科学探索与人文思辨的思想碰撞，邀请您共同探讨“思想钢印”从科幻想象走向现实的边界。\n适合对象：\n神经科学研究人员、科技伦理学者、AI与脑机接口工程师、科幻迷，以及关注未来人机交互的各界人士。\n特邀学术报告嘉宾（按姓氏拼音排序）\n李济安，加州大学圣地亚哥分校神经科学博士生在读。2016年本科毕业于中国科学技术大学生命科学学院（计算机科学双学位），2019年硕士毕业于中国科学技术大学统计系。 长期从事计算神经科学、认知神经科学、人工智能等方面交叉科学研究。研究方向包括利用基于数理工具和深度学习的计算建模研究生物脑的知觉、记忆、学习和决策等功能。目前主要研究方向包括：(1)认知决策计算机制的自动发现；(2)深度学习模型和生物脑的异同；（3）反向传播算法的生物可行性；（4）决策机制的计算精神病学；(5)大语言模型的机制可解释性。目前获得卡弗里脑与认知研究所创新研究基金的资助。研究成果在Nature, Nature Human Behaviour等期刊发表。报告主题为《利用微型循环神经网络自动发现认知策略》。\n刘泉影博士，南方科技大学长聘副教授，博导，神经计算与控制实验室(NCC lab)负责人。致力于从人工智能、控制理论和脑科学交叉融合的视角，发展基于AI的多模态神经解码算法，构建数据驱动的AI孪生脑模型，研发智能化的闭环神经调控系统，推动“读出-写入”双向脑机接口技术的发展，为解码脑功能和干预神经疾病提供全新范式，以一作/通讯作者在Nature Methods、The Innovation等期刊，NeurIPS、ICML、ICLR等机器学习顶会上发表论文60余篇。报告主题为《数据驱动的AI孪生脑》。\n罗逸飞博士，香港大学数据科学研究院与心理系助理教授，博士生导师，主要研究方向为计算神经科学 \u0026amp; 计算认知科学。报告主题为《可微分3D渲染与视觉认知》。\n张洳源博士，目前担任上海交通大学心理学院和上海交通大学医学院附属精神卫生中心双聘课题组长，领导认知计算神经科学和脑影像课题组。长期致力于脑科学与类脑智能的交叉研究，综合运用心理物理学、贝叶斯概率模型、深度学习模型、神经调控以及核磁共振等研究手段，探索人脑和人工智能的神经计算机制。以第一或者通讯作者(含共同)在Nature Human Behaviour、AMPPS、PNAS、eLife、J Neurosci、PLoS Comput Biol等杂志发表认知神经科学论文。张洳源的类脑计算研究还在世界顶级机器学习会议(中国计算机A类)ICML和IJCAI发表。目前担任BMC Neuroscience、Psychoradiology、Brain-X等杂志编委，还担任eLife, Cerebral Cortex等脑科学杂志和ICML, NeurIPS, IJCAI, ICLR, CVPR等世界顶级机器学习会议审稿人和ICML2025, NeurIPS 2024,2025的领域主席(area chair)。张洳源的研究先后受到国家自然科学基金、科技部项目和上海市自然科学基金等项目的支持。张洳源先后获得上海市浦江人才计划、上海市海外高层次人才和上海市科技青年35人引领计划提名奖和世界人工智能大会青年优秀论文提名奖(排二)。报告主题为《为什么我们需要计算建模来回答科学问题？》。\n伍海燕博士，澳门大学协同创新研究院ANDlab PI（https://andlab-um.com/），加州理工学院访问学者。加入澳门大学之前，伍海燕教授于北京师范大学获得博士学位，并曾在中国科学院心理研究所担任副研究员。目前论文总被引用超2200次。近五年，以最后通讯作者在Nature Communications, eLife, Scientific Data, Neuroimage, Annals of the New York Academy of Sciences, Human Brain Mapping, Behavior Research Methods 等神经科学和心理学期刊发表论文多篇，神经科学相关专利3项。入选2023年 “脑科学与类脑智能科创新青年30人”。她的研究致力于引入跨学科技术框架，结合人工智能与脑成像、计算模型、颅内及颅外神经信号、神经调控、虚拟现实和大数据，以探索大脑中情绪与决策的交互机制。报告主题为《社会道德决策的神经与计算机制》。\n报名方式\n请扫描二维码填写问卷报名（线下参加人数限制60人）。特别提醒：（1）本活动不含报名费，参加者食宿自理；（2）自由报名，择优录取；（3）名额有限，早报早得。如果行程有变，及时联系志愿者，将名额让给其他人。 Click the link to register ( https://www.wjx.cn/vm/tYCvkf3.aspx).\n","date":1752105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1752105600,"objectID":"026aa99d547ccc6d9c0fb18f7dbc2b42","permalink":"https://terryzang.github.io/news/2025-7-summer_hackthon/","publishdate":"2025-07-10T00:00:00Z","relpermalink":"/news/2025-7-summer_hackthon/","section":"news","summary":"COSN Summer Hackathon又双叒来啦！！！通过2022年 ～ 2024年的三次活动，越来越多的小伙伴有机会参与了Hackathon。今年的Hackathon将以“AI + 脑科学”为主题，聚焦人工智能技术在脑科学领域的探索与应用，欢迎大家提出相关的Project（提交的具体流程之后会公布）！\n","tags":null,"title":"COSN Summer Hackathon 2025开始报名啦！","type":"news"},{"authors":null,"categories":null,"content":"","date":1750723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750723200,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://terryzang.github.io/contact/","publishdate":"2025-06-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":["COSN Team"],"categories":null,"content":"走到2025年，neurochat神聊来到了第6年！在今年，neurochat 神聊2025会议将继续在线下线上混合展开，坚持小而精的组织形式。今年组委会将和部分青年报告人相聚太湖湖畔的苏州！\n","date":1749513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1749513600,"objectID":"a3de7ee4aa8012e829d96ccc3acf9aff","permalink":"https://terryzang.github.io/news/2025-6-10/","publishdate":"2025-06-10T00:00:00Z","relpermalink":"/news/2025-6-10/","section":"news","summary":"走到2025年，neurochat神聊来到了第6年！在今年，neurochat 神聊2025会议将继续在线下线上混合展开，坚持小而精的组织形式。今年组委会将和部分青年报告人相聚太湖湖畔的苏州！\n","tags":null,"title":"neurochat神聊2025在线学术会议将于6月14日召开!","type":"news"},{"authors":["OpenTalks Team"],"categories":null,"content":"分享嘉宾:\n刘泉影，南方科技大学长聘副教授，博导，PI。2010年/2013年毕业于兰州大学信息学院，获学士/硕士学位。2017年于瑞士苏黎世联邦理工学院获博士学位，其后在美国加州理工学院从事博士后研究工作。2019年8月回国，在南方科技大学成立神经计算与控制实验室（NCC lab）。主要研究方向是多模态神经信号处理算法、脑网络动力学建模、神经编解码算法、神经调控优化算法等工作，致力于从人工智能、控制理论和脑科学交叉融合的视角，发展基于AI的多模态神经解码算法，构建数据驱动的AI孪生脑模型，研发智能化的闭环神经调控系统，推动“读出-写入”双向脑机接口技术的发展，为解码脑功能和干预神经疾病提供全新范式，已在Nature Methods、The Innovation等期刊，NeurIPS、ICML、ICLR等机器学习顶会上发表论文60余篇。 ","date":1748390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1748390400,"objectID":"0959ef49982349fece0444571735bf58","permalink":"https://terryzang.github.io/event/opentalk/2025_88/","publishdate":"2025-05-28T00:00:00Z","relpermalink":"/event/opentalk/2025_88/","section":"event","summary":"毕楷文，香港大学社会工作及社会行政学系博士生在读。研究聚焦童年与青少年逆境等潜在性创伤事件 (potentially traumatic events [PTEs]) 对情绪调节和心理健康的跨生命周期影响及因果推断在心理学纵向研究中的应用。以第一作者/通讯作者（含共同第一）身份在 JAMA Psychiatry、Advances in Methods and Practices in Psychological Science、Journal of Psychopathology and Clinical Science、Journal of Adolescent Health, Child Abuse and Neglect, Journal of Psychiatric Research等国际精神病学与心理学期刊发表论文。","tags":["OT"],"title":"OpenTalks #88 | 运用敏感性分析评估心理学纵向研究中未测量混淆因素的干扰风险","type":"event"},{"authors":["COSN Team"],"categories":null,"content":"您是否热衷于提高科学研究的可重复性？Psychological Science这一期刊正在招募志愿者加入他们的REPEAT网络，一个用来检验计算可重复性(computational reproducibility)的小组。\n背景 Psychological Science最近引入了新的政策来提高透明度和严谨性 (Hardwicke \u0026amp; Vazire, 2024)，其中包括要求实证文章必须具备计算可重复性（这意味着报告的结果可以通过对原始数据重复原始分析来独立重现）[1]。期刊正在建立一个志愿者网络，在文章发表前验证其计算可重复性[2]。欢迎同行积极申请，包括研究生和早期职业研究人员。 我将做什么？ 验证提交给《心理科学》的文章的计算可重复性[3]。 向作者提供建设性反馈，以增强其工作的可重复性。 涉及多少工作量？ 文章将随机分配。如果您太忙，可以拒绝分配。 可重复性检查通常涉及与作者进行几轮来回沟通，总时间差异很大；我们估计每篇手稿需要 1 ～ 10 小时。 要加入 REPEAT 网络，您每年应愿意完成至少四次可重复性检查。每年，我们将更新网络，询问您是否希望继续成为成员。 有什么要求？ 能够证明自己在心理学（或相关领域）有重现分析的能力/经验。 高度的责任心、注重细节以及对科学诚信的承诺。 如何报名成为志愿者？ 请填写此 Google 表格[4]提交意向表达。如果您有任何问题，请发送电子邮件至《心理科学》高级 STAR 编辑 Tom Hardwicke (tom.hardwicke@sydney.edu.au)。 [1] 此要求有一些例外情况；例如，出于伦理原因无法共享数据时。\n[2] 目前，这些检查由期刊的统计、透明度和严谨性 (STAR) 团队负责；然而，我们相信一个更大的网络将有助于我们获得更广泛的分析和软件能力，并更有效地满足需求。\n[3] 具体而言，您的目标是使用作者共享的分析脚本和数据来重现手稿中报告的所有数值。我们要求作者提供组织良好且清晰记录的文件，逐步解释如何重现手稿中报告的结果。如果您无法轻松重现结果，您无需深入探索来理解其，只需要告知作者问题并要求他们进行解决。大多数研究人员并未接受如何使分析具有可重复性的培训，因此您可能需要一些这方面的训练。\nhttps://docs.google.com/forms/d/e/1FAIpQLSfCtU1TP-G4ztChWTqtlwj_rj7R8WT_UE2I_22VJeAamuKv-w/viewform\n","date":1748044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1748044800,"objectID":"b750a60a423b35671fe303af74841c5d","permalink":"https://terryzang.github.io/news/2025-5-ps_repeat/","publishdate":"2025-05-24T00:00:00Z","relpermalink":"/news/2025-5-ps_repeat/","section":"news","summary":"您是否热衷于提高科学研究的可重复性？Psychological Science这一期刊正在招募志愿者加入他们的REPEAT网络，一个用来检验计算可重复性(computational reproducibility)的小组。\n","tags":null,"title":"志愿者招募: Psychological Science REPEAT网络","type":"news"},{"authors":["OpenTalks Team"],"categories":null,"content":"分享嘉宾: Thomas Klebel is a member of the Open and Reproducible Research Group and a Senior Researcher at Know Center. In his research, he investigates unintended consequences of current implementations of Open Research, ways of improving the reproducibility of research findings, and avenues for sustainable business models around open research infrastructure. With a focus on quantitative methods of inquiry, he is also keenly interested in causal modelling and ways of improving research practice. Thomas completed his doctoral studies in Sociology in 2024 and holds a degree in Music Performance from the University of Performing Arts Graz. You can find him on ORCID and LinkedIn. ","date":1747922400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747922400,"objectID":"b38a18e6ac8ed087631fedf1d1e1f519","permalink":"https://terryzang.github.io/event/opentalk/2025_86/","publishdate":"2025-07-10T00:00:00Z","relpermalink":"/event/opentalk/2025_86/","section":"event","summary":"开放科学的学术影响","tags":["OT"],"title":"OpenTalk No.86 | The Academic Impact of Open Science","type":"event"},{"authors":["OpenTalks Team"],"categories":null,"content":"","date":1747872000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747872000,"objectID":"6b0dfb0a25eeb11a5344afcbb6df95c1","permalink":"https://terryzang.github.io/event/opentalk/2025_87/","publishdate":"2025-05-22T00:00:00Z","relpermalink":"/event/opentalk/2025_87/","section":"event","summary":"任建勋，昌平实验室科学家，哈佛医学院访问学者。研究方向为个体化脑功能影像与神经调控。以第一或通讯作者身份在Nature Methods、Nature Communications、Annals of Neurology、Medical Image Analysis、Brain Stimulation、Human Brain Mapping、Cerebral Cortex等期刊上发表SCI论文14篇，共发表论文29篇，引用超1000次；开发的DeepPrep脑影像预处理工具上线3个月，下载已超5000次。","tags":["OT"],"title":"OpenTalks #87 | DeepPrep: 高效fMRI预处理平台及其在精准神经调控中的应用","type":"event"},{"authors":["COSN_Terry","COSN_John"],"categories":null,"content":"编者荐语:Elife作为科学出版的先行者，正在积极探索不同于当前“发表 vs 拒稿”的模式，而是公开审稿意见和质性评分对稿件进行评估。可以从elife新主编的访谈中看到这个新模式是研究者，而不是出版商，所做出的努力。\n","date":1747353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1747353600,"objectID":"d0545d05f64a35418d3c5b92b48d1401","permalink":"https://terryzang.github.io/news/2025-5-elife/","publishdate":"2025-05-16T00:00:00Z","relpermalink":"/news/2025-5-elife/","section":"news","summary":"编者荐语:Elife作为科学出版的先行者，正在积极探索不同于当前“发表 vs 拒稿”的模式，而是公开审稿意见和质性评分对稿件进行评估。可以从elife新主编的访谈中看到这个新模式是研究者，而不是出版商，所做出的努力。\n","tags":null,"title":"专访eLife主编：失去影响因子，中国来稿减少了80%","type":"news"},{"authors":["OpenTalks Team"],"categories":null,"content":"","date":1746748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746748800,"objectID":"9455b6a78f5fc15bcb177746edb4c2a1","permalink":"https://terryzang.github.io/event/opentalk/2025_85/","publishdate":"2025-05-09T00:00:00Z","relpermalink":"/event/opentalk/2025_85/","section":"event","summary":"沈波博士是纽约大学医学院的研究科学家，博士毕业于北京大学心理与认知科学学院，本科毕业于上海交通大学物理系。他主要借助动态神经网络模型、动态行为测量（鼠标追踪）、行为计算建模、fMRI脑成像等手段研究决策的认知动态过程和神经网络计算机制。其研究发表在Nature Communications, PNAS, eLife, Neuroimage, Nature Reviews Psychology等具有国际影响力的心理学、神经科学等学术期刊。","tags":["OT"],"title":"OpenTalks #85 | 决策过程中噪声的情景依赖性","type":"event"},{"authors":["OpenTalks Team"],"categories":null,"content":"","date":1746316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746316800,"objectID":"dec5601cd201523ee95e796b35a92da5","permalink":"https://terryzang.github.io/event/opentalk/2025_84/","publishdate":"2025-05-04T00:00:00Z","relpermalink":"/event/opentalk/2025_84/","section":"event","summary":"Dr. Ru-Yuan Zhang is the principal investigator at the School of Psychology, Shanghai Jiao Ton University and the Shanghai Mental Health Center. His research focuses on the intersection of brain science and brain-inspired artificial intelligence. His work has been published in journals including Nature Human Behaviour, AMPPS, PNAS, eLife, J Neurosci, and PLoS Computational Biology. His work on brain-inspired computing has also been featured at top machine learning conferences, including ICML and IJCAI. Dr. Zhang serves as an active reviewer for both neuroscience and AI journals including eLife and TLNNS, as well as major AI conferences like ICML, NeurIPS, IJCAI, ICLR, and CVPR. He also serves as an area chair for ICML 2025 and NeurIPS 2024/2025.","tags":["OT"],"title":"OpenTalks #84 | 视觉学习的计算神经机制","type":"event"},{"authors":["COSN_John"],"categories":null,"content":"本周，一本全新的钻石开放获取期刊 ——《稳健性报告期刊》（Journal of Robustness Reports，简称 JRR）正式创刊(网址：https://scipost.org/JRobustRep)。该期刊专注于发表对已发表实证研究成果的简短再分析。\nWCRI 2026向全球所有学科，职业阶段和专业职级开放，欢迎研究诚信方面的各利益相关方踊跃参加，包括但不限于大学、研究机构、资助者、出版商和政府代表。第9届WCRI将提供充满活力和互动性的活动，包括突破性的研究、深刻的反思以及有影响力的政策讨论，旨在吸引学术界、从业人员和决策者的参与。\nThe majority of empirical research papers only report a single main analytical result, which is usually carried out by a single analysis team (often also the team responsible for the experimental design and data collection) according to a single analysis plan. However, the “multi-analyst projects” in recent years have shown that different analysis teams often adopt their own unique methods, resulting in significant differences in conclusions. In fact, there is no single optimal statistical analysis plan, and different reasonable plans may lead to different conclusions. The strong variability of conclusions indicates their vulnerability, which is highly dependent on the specific analysis path. The key issue is that without independent analyses by multiple teams, it is difficult to assess the robustness of the conclusions. We recently proposed that for empirical research with significant scientific or social significance, 2-3 short reanalysis reports completed by independent experts should be attached [1]. To verify the feasibility and cognitive value of this method, we established the “Robustness Report Journal”, dedicated to publishing reanalyses of empirical results. This article outlines the journal’s positioning, workflow, and article format of JRR. We hope that JRR can promote reanalysis to become a routine practice in the field of empirical science.\nJRR requires that the main body of the “Stability Report” should not exceed 500 words (excluding acknowledgments, references, chart explanations and title page). Only one presentation element (either a figure or a table) is allowed, and other supplementary materials must be presented in the form of online appendices. The response from the original author and the editor’s summary are also limited to 500 words and one presentation element, but they do not need to follow the above chapter structure. The article template is available in both Word and LaTeX versions.\n图1 The original intention behind setting the word limit: JRR hopes to encourage mainstream empirical journals to adopt this format, attaching robustness reports to important studies – a 500-word length is comparable to that of a “comment” or “letter to the editor” (most journals are already familiar with such formats), and the implementation cost is extremely low.\n","date":1745280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1745280000,"objectID":"86487a1e3e1b5b22ac9d4d1a800a7e72","permalink":"https://terryzang.github.io/news/2025-4-22/","publishdate":"2025-04-22T00:00:00Z","relpermalink":"/news/2025-4-22/","section":"news","summary":"本周，一本全新的钻石开放获取期刊 ——《稳健性报告期刊》（Journal of Robustness Reports，简称 JRR）正式创刊(网址：https://scipost.org/JRobustRep)。该期刊专注于发表对已发表实证研究成果的简短再分析。\nWCRI 2026向全球所有学科，职业阶段和专业职级开放，欢迎研究诚信方面的各利益相关方踊跃参加，包括但不限于大学、研究机构、资助者、出版商和政府代表。第9届WCRI将提供充满活力和互动性的活动，包括突破性的研究、深刻的反思以及有影响力的政策讨论，旨在吸引学术界、从业人员和决策者的参与。\n","tags":null,"title":"新刊｜钻石开放获取模式的《稳健性报告期刊》","type":"news"},{"authors":["OpenTalks Team"],"categories":null,"content":"","date":1744243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744243200,"objectID":"06f933f66cee59b4f25e28ec974e5d81","permalink":"https://terryzang.github.io/event/opentalk/2025_83/","publishdate":"2025-04-10T00:00:00Z","relpermalink":"/event/opentalk/2025_83/","section":"event","summary":"孙良龙，北京师范大学在读博士生，主要从事神经影像大数据与人脑复杂网络研究。共发表SCI论文10篇，其中以第一作者和通讯作者（含并列）在Nature Neuroscience（封面文章）, Science Bulletin, NeuroImage等发表论文4篇。受邀在第30届国际人脑图谱学会（OHBM）教育课程作40分钟特邀报告。获国际医学磁共振学会（ISMRM）杰出摘要奖（Merit Abstract Award）、教育津贴奖（Educational Trainee Stipend）、博士生国家奖学金（2022/2024）。主持国家自然科学基金青年学生基础研究项目（博士研究生），入选中国科协青年人才托举工程博士生专项。","tags":["OT"],"title":"OpenTalks #83 | 人脑功能网络的毕生发展参考模型","type":"event"},{"authors":["OpenTalks Team"],"categories":null,"content":"分享嘉宾: 程溪，北京师范大学心理学博士研究生，本科毕业于南京师范大学心理学院。研究方向聚焦社会认知领域，目前主要开展两方面工作：1）开发简便测量和可用于文本分析的社会关系量化工具，探索社会认知结构的文化差异及其历史演变规律；2）探究幽默与心理健康的关系及其认知神经基础。 ","date":1743107400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1743107400,"objectID":"c8b64037f347c82e7e3fabe232802aee","permalink":"https://terryzang.github.io/event/opentalk/2025_82/","publishdate":"2025-03-23T00:00:00Z","relpermalink":"/event/opentalk/2025_82/","section":"event","summary":"跨文化、跨时空的人际关系概念结构。","tags":["OT"],"title":"OpenTalks #82 | 跨文化、跨时空的人际关系概念结构","type":"event"},{"authors":["COSN Team"],"categories":null,"content":"第九届世界研究诚信大会（9th World Conference on Research Integrity, WCRI）将于2026年5月3日至6日在加拿大温哥华的威斯汀岸酒店举行。\nWCRI 2026向全球所有学科，职业阶段和专业职级开放，欢迎研究诚信方面的各利益相关方踊跃参加，包括但不限于大学、研究机构、资助者、出版商和政府代表。第9届WCRI将提供充满活力和互动性的活动，包括突破性的研究、深刻的反思以及有影响力的政策讨论，旨在吸引学术界、从业人员和决策者的参与。 赶紧将会议加入您的日程表，来加入这个充满活力的学术聚会，在这里交流想法，认识同行，共同塑造未来的世界研究诚信。 点击链接访问会议网站: https://wcri2026.org\n会议提案\nWCRI 2026组委会欢迎有关会前研讨会(Pre-Conference Workshop Proposal)、全体会议(Plenary Session Proposal)、专题讨论会(Symposium Proposal)以及重点专题(Focus Track Proposal)的提案。提交的提案应与广泛的利益相关者和学科领域相关。鼓励就会议主题“本土视角(Indigenous ways of being)”、“人工智能(artificial intelligence)”和“研究安全(research security)”进行提案。请注意，所有会议提案均需由规划委员会或WCRI理事会成员（https://wcri2026.org/committees-boards/）提交或支持。 提案网址（提交截止日期：2025年4月14日）： https://wcri2026.org/call-for-proposals/\n赞助和展览\n世界研究诚信会议基金会（WCRIF）诚邀赞助商和/或参展商参与这项顶级盛会，共同打造WCRI 2026，期待本届盛会对科研诚信的未来产生持久的影响。赞助商级别从青铜到白金不等。此外，WCRIF还提供各种自选赞助机会。如需了解更多赞助套餐和优惠详情，可访问WCRI 2026赞助页面（https://wcri2026.org/opportunities/）或联系赞助招募团队（mailto: wcri2026-sponsorship@venuewest.com）讨论您的参与事宜。WCRIF期待与您合作！ 第六、第七和第八届WCRI提交摘要的预注册率\nWCRI委员会调查了在第六、第七和第八届世界研究诚信大会上提交的实证研究摘要的预注册率。结果表明，随着时间的推移，预注册率停滞在28%而没有提高。然而，声称预注册的研究的可验证性确实有所提高率，从44%上升到88%。与研究特征和提交摘要研究者特征的关联，以及未进行预注册的原因，可参见已发表的预印本（https://osf.io/preprints/metaarxiv/cn6jf_v1）。该调查的结论是：科研诚信领域的研究人员应该更加言行一致。 WCRI早期职业研究人员和专业人员网络\nWCRI早期职业研究人员和专业人员（ECRP）网络在雅典第八届WCRI会议期间成立，现今已有半年。该网络首次虚拟聚会将于2025年3月19日举行，持续1小时。会议开始时间为北京/马来西亚/新加坡晚上8点，南非下午2点，荷兰下午1点，秘鲁上午7点，华盛顿特区上午8点。点击会议注册链接（https://docs.google.com/forms/d/e/1FAIpQLSciod1t8al36-LKkb1MneyNx0_LCUCN8cHODuoP-3tdoDTSEA/viewform）可报名参加此次虚拟会议。如需了解更多会议详情，可联系De-Ming Chau (chau.deming@gmail.com)。","date":1742169600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1742169600,"objectID":"965e3a68c876f7b9b7fc90843ce0bdff","permalink":"https://terryzang.github.io/news/2025-3-wcri/","publishdate":"2025-03-17T00:00:00Z","relpermalink":"/news/2025-3-wcri/","section":"news","summary":"第九届世界研究诚信大会（9th World Conference on Research Integrity, WCRI）将于2026年5月3日至6日在加拿大温哥华的威斯汀岸酒店举行。\n","tags":null,"title":"会议通知 | 第九届世界研究诚信大会（WCRI）简报 #1","type":"news"},{"authors":["COSN_John"],"categories":null,"content":"开放科学（Open Science）作为一种新兴的科研范式，正在全球范围内掀起一场深刻的变革。中国作为全球科技强国之一，正在积极拥抱开放科学，并努力在全球开放科学治理中发挥引领作用。\n","date":1741910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741910400,"objectID":"08b21770b112f6d6562a4a78cc67539f","permalink":"https://terryzang.github.io/news/2025-3-14/","publishdate":"2025-03-14T00:00:00Z","relpermalink":"/news/2025-3-14/","section":"news","summary":"开放科学（Open Science）作为一种新兴的科研范式，正在全球范围内掀起一场深刻的变革。中国作为全球科技强国之一，正在积极拥抱开放科学，并努力在全球开放科学治理中发挥引领作用。\n","tags":null,"title":"杨卫院士及中国科学院文献情报中心团队观点文章 | 开放科学带来的三道阳光、三个转变、四重挑战","type":"news"},{"authors":["OpenTalks Team"],"categories":null,"content":"","date":1741824000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741824000,"objectID":"e398d88f1a9e89804876e7c22dd62ca1","permalink":"https://terryzang.github.io/event/opentalk/2025_81/","publishdate":"2025-03-13T00:00:00Z","relpermalink":"/event/opentalk/2025_81/","section":"event","summary":"马庆，华东师范大学紫江青年研究员。2024年9月加入华东师范大学心理与认知科学学院。2020年博士毕业于北京师范大学认知神经科学与学习国家重点实验室。2020-2024年在复旦大学类脑智能科学与技术研究院从事博士后研究。研究主要利用大数据优势，整合多模态数据（包括但不限于行为测量、磁共振影像、基因组等），围绕神经发展、精神健康与疾病两大方向进行展开。相关研究成果以第一（含共同第一）作者的身份发表在BMC Medicine, Biological Psychiatry, Schizophrenia Bulletin, Journal of Adolescent Health, European Child \u0026 Adolescent Psychiatry, Cortex等国际高水平期刊。","tags":["OT"],"title":"OpenTalks #81 | 阈下抑郁发展进程的影响因素","type":"event"},{"authors":["OpenTalks Team"],"categories":null,"content":"","date":1741564800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741564800,"objectID":"f23f6687542b5be4b44fe0a8c951acdb","permalink":"https://terryzang.github.io/event/opentalk/2025_80/","publishdate":"2025-03-10T00:00:00Z","relpermalink":"/event/opentalk/2025_80/","section":"event","summary":"Necati Çağatay Gürsoy is a cognitive scientist and neuroscience researcher. He holds a BS in Electrical and Electronics Engineering from Bilkent University (2016) and an MS in Cognitive Science from Middle East Technical University (2019).Currently, Gürsoy is pursuing a PhD at the Central Institute of Mental Health in Heidelberg, Germany, working in Dr. Gordon Feld's research group. His doctoral research focuses on sleep and neuroplasticity, specifically investigating the link of addiction and olfactory neuroplasticity and human multi-feature learning.His research interests include sleep and memory processes, addiction research, neural networks, and facial recognition. Before his PhD, he worked as a Teaching Assistant and as an Engineer.","tags":["OT"],"title":"OpenTalks #80 | ARIADNE: 科研资源指北","type":"event"},{"authors":["OpenMinds Team"],"categories":null,"content":"","date":1731801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1731801600,"objectID":"d772e554f67b6a39612c145d26f41a35","permalink":"https://terryzang.github.io/event/openmind/2024_3.12/","publishdate":"2024-11-17T00:00:00Z","relpermalink":"/event/openmind/2024_3.12/","section":"event","summary":"Lakens, D., McLatchie, N., Isager, P. M., Scheel, A. M., \u0026 Dienes, Z. (2020). Improving inferences about null effects with Bayes factors and equivalence tests. The Journals of Gerontology: Series B, 75(1), 45–57. https://doi.org/10.1093/geronb/gby065","tags":["OM"],"title":"OpenMinds 3.0 | 第12期：频率论or贝叶斯","type":"event"},{"authors":["OpenMinds Team"],"categories":null,"content":"","date":1730592000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730592000,"objectID":"4135682c90ecc5aa7ea4b94468f02213","permalink":"https://terryzang.github.io/event/openmind/2024_3.11/","publishdate":"2024-11-03T00:00:00Z","relpermalink":"/event/openmind/2024_3.11/","section":"event","summary":"Heck, D. W., Boehm, U., Böing-Messing, F., Bürkner, P.-C., Derks, K., Dienes, Z., Fu, Q., Gu, X., Karimova, D., Kiers, H. A. L., Klugkist, I., Kuiper, R. M., Lee, M. D., Leenders, R., Leplaa, H. J., Linde, M., Ly, A., Meijerink-Bosman, M., Moerbeek, M., … Hoijtink, H. (2023). A review of applications of the Bayes factor in psychological research. Psychological Methods, 28(3), 558–579. https://doi.org/10.1037/met0000454","tags":["OM"],"title":"OpenMinds 3.0 | 第11期：贝叶斯因子","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":" 原文信息Kozlov, M. (2024). So you got a null result. Will anyone publish it?. Nature 631, 728-730. https://doi.org/10.1038/d41586-024-02383-9\n译者/校对者列表OpenTransfer 自动翻译工作流程；敬俊林，金淑娴\n摘要研究人员已经尝试了各种策略，以增加文献对阴性结果的收录。《Nature》对此进行了调查，探讨这些策略是否真正奏效。 正文 进化生物学家Natalie Pilakouta提出了一个她认为应当很容易被验证的假设：生活在冰岛地热温泉中的鱼类，应该比生活在附近较冷湖泊中的同类鱼更倾向于温暖的水。然而，经过两年的研究，她却依然没有得到明确的结论——当提供两种水温的选择时，这两个鱼群都显示出对凉水的偏好。 她感到非常失望，因为她明白，发表这样的研究结果将面临巨大的困难。此外，她迫切希望分享这个反直觉的发现，因为它挑战了一个广为接受的假设：即水生生物在面对全球变暖时，可能会进化出对高温环境的偏好。 Pilakouta目前在英国圣安德鲁斯大学任职，她算是少数的幸运儿之一。她的研究历经了六年的时间，向七家期刊投稿，终于在2023年1月得以发表。然而，她的故事揭示了学术界长期存在的“文件抽屉问题”（file-drawer problem）——那些未能发现变量间关系，或得出与既有假设相悖的零结果和阴性结果的研究，往往被搁置；而具有显著结果的研究更容易被发表。2022年，一项在法国进行的科学家调查显示，75%的受访者愿意发表他们的零结果研究，但只有12.5%的人成功发表。随着时间的推移，这种发表偏倚（publication bias）扭曲了科学记录，对显著结果的过度关注甚至促使研究人员选择性地报告数据或夸大统计显著性。这不仅浪费了时间和资金，还导致研究人员可能重复进行那些已经被研究但未发表的实验。有证据表明，这一问题正变得更加严重，阴性结果的发表数量正在减少。资助方、出版商和研究人员对此并非无所作为。如今，许多期刊鼓励研究团队在实验开始前提交研究计划和方案，期刊则会提前对其进行审查，并承诺无论结果如何，都会发表。至今，已有数百家期刊采用这种“注册报告”（registered report）的模式，自2018年以来，采用这种方式的期刊数量已翻了一倍。 位于弗吉尼亚州夏洛茨维尔的开放科学中心执行董事Brian Nosek提到：“集中关注阳性结果并不是唯一的科学研究方式”。Nosek与全球各地的研究人员一起，致力于重塑科研的运作方式，挑战研究成功的定义。这不仅包括打击诸如抄袭等恶劣的科研不端行为，还呼吁遏制一些“较轻”的违规行为，比如选择性报告，旨在促使更多阴性结果的发表。这些变化已经开始在出版行业逐渐显现，随着预印本服务器的增多，出版商们采用新的手稿格式，推出专门发表零结果的期刊，并呼吁专题刊物。 隐藏的结果\n研究人员对“文件抽屉问题”已经关注了数十年。然而，直到2010年代初，这一问题所引发的更大困境才逐渐浮出水面。当时，研究人员尝试重复多个心理学和医学领域的基础实验，却未能取得成功。这促使科学家们开始探讨这一“可重复危机”的范围以及发表偏倚的问题。 研究人员的研究揭示了阴性结果被埋没的频率。他们对超过30万份科学会议报告的分析显示，科学家们通常会尝试将这些报告转化为论文，但其中只有不到40%被发表在同行评审的期刊上，而阴性或零结果的研究往往比阳性结果更少被公布。 发表偏倚的程度因学科和国家而异，但这一问题似乎随着时间的推移愈加严重。一项对1990年至2007年间4600篇论文的分析发现，这段时间内发表偏倚增加了22%。 发表偏倚可能会对现实世界产生影响。例如，在74项评估抗抑郁药物的注册临床试验中，近三分之一的试验结果未被公开，这些试验很可能显示阴性结果而非阳性结果。仅从已发表的结果来看，94%的试验似乎得出了积极的结论，而药物审批委员会认为只有51%的试验结果为阳性。 选择性报告导致了对药物疗效的夸大认识，这种情况在主要包含阳性结果的文献综述中尤为严重。尽管美国的法律要求临床试验的研究人员无论结果如何都必须报告他们的结果，但实际情况仍然受到经济利益和试验参与者的期望影响，Nosek表示，这些结果反映了“我们还有很长的路要走”。 此外，斯坦福大学医学院的Steven Goodman表示，阴性或零结果的研究通常比阳性结果的研究受到更严格的审查，尤其是在阳性结果“验证了我们认为是正确的东西”时，这种严格审查显得尤为突出。 印第安纳大学南本德分校的认知神经科学家Jessica Payne指出，人们仍然持有这样的观点：如果研究结果为阴性或零结果，科学家的研究设计必然存在缺陷。 事实上，根据对480名经济学家的调查，零结果的研究被认为比具有显著结果的研究更难发表，即使样本量等因素保持不变，也会被认为质量较差且重要性较低——这种现象被称为“零结果惩罚”。Goodman表示，得到大效应量的研究应比零结果的研究受到更多的审查。 文化偏倚\n可重复危机清楚地表明：学术界的激励机制并不总是与研究的诚信和可重复性保持一致。荷兰乌特勒支大学的元科学家Anne Scheel表示，这在很大程度上解释了为什么如此少的阴性结果能够被发表。 Scheel认为，学术不端行为和发表偏倚的根源在于人们对“发表或灭亡”文化的共识和认同，这种文化由学术机构、研究资助方、学术期刊和科学家自身共同维持，奖励那些在著名期刊上发表研究成果的研究人员。 但一些批评者指出，这些学术守门人存在偏见，他们认为资助方和顶尖期刊往往追求新颖且引人注目的发现。澳大利亚墨尔本大学的心理学家、《Psychological Science》的编辑Simine Vazire表示，期刊编辑们会担心充满零结果的刊物会吸引更少的读者。 Nosek指出，这在研究人员和期刊之间形成了一个紧密的反馈循环。为了用看起来新颖且值得注意的发现吸引期刊，一些科学家可能会在看到结果后更改假设，或只公布部分数据，甚至使用统计手段来美化结果。 积极的解决方案\n为了鼓励更多研究人员报告零结果，期刊和资助方正在尝试几种方案。其中最重要的变化之一是“预注册”（pre-registration）的推广（见图1），即研究人员必须在研究开始时在公共数据库中声明他们的假设和打算测量的结果（这一做法在临床试验中已成为常规）。 Nosek 说，预注册模型促使研究人员忠实于研究的初衷，但它并未解决研究人员在提交研究结果到期刊时的偏倚问题，也未能消除期刊编辑和审稿人在决定是否发表时的偏见。 相反，Nosek和同事们专注于推广和评估“注册报告”模型——这一模型类似于“预注册”报告，但其初步计划由期刊发布，并承诺进行同行评审和对结果的发表。 初步数据显现出注册报告的良好前景：Scheel 和她的同事比较了 71 个注册报告与 152 个标准心理学手稿的结果，发现注册报告中有 44% 显示出阳性结果，而标准出版物中则有 96% 显示阳性结果（见图2）。Nosek 和他的团队发现，审稿人对心理学和神经科学领域中的注册报告在研究严谨性和质量指标上的评分普遍高于标准模式下发表的论文。自 2012 年这一格式推出以来，尽管最初只有少数期刊采纳了注册报告，但现在已有超过 300 个期刊提供这种形式，包括 《PLoS ONE》 和由 Springer Nature 出版的《Nature》（Nature 新闻团队与期刊团队的编辑流程相互独立）。虽然 Nature 从 2023 年 2 月起提供注册报告的形式，但尚未发表任何注册报告，其姊妹期刊《Nature Human Behaviour》 已有相关发表。 尽管这种形式（注册报告）日益受到欢迎，但研究人员表示仍存在一些问题需要解决。今年早些时候，瑞士巴塞尔大学的睡眠研究员Christine Blume发表了她的第一篇注册报告，研究光线如何影响人体生物节律，刊登在《Nature Human Behaviour》 期刊上。她表示，尽管她很喜欢在数据收集之前就能收到关于研究设计的反馈——“这让我觉得，我拥有了最佳的研究设计来回答我想解决的问题”——但她发现反馈过程可能持续数月，特别是当研究经费有时间限制时，这可能让人感到沮丧。 Nosek指出，这些实际问题至关重要。他坦承，自己关于注册报告质量的那篇论文本身，并不是一篇注册报告，这是因为资助资金即将到期，团队没有时间经历冗长的审批程序来完成分析。他说，“我们不能忽视实用性，但可以思考如何降低门槛，以便处理更多此类情况”。 提供注册报告的期刊在各个学科之间分布不均；大多数期刊集中在心理学领域，最近也开始出现在神经科学领域。很少有物理科学期刊采用这种形式——尽管零结果，如瑞士日内瓦附近的大强子对撞机自希格斯玻色子以来未能发现新的亚原子粒子，依然是科学进展的重要组成部分。来自英国爱丁堡大学的转化医学研究员和元科学家Emily Sena指出，特别是在预临床领域，几乎没有学者愿意尝试这种形式，尤其是在研究人员在开始实验之前就面临诸多繁琐程序时。 Vazire表示，这种形式在研究人员中推广得很慢，“我们并没有收到许多注册报告的提交”。 Sena和她的同事一直在宣传注册报告，并帮助期刊编辑增强审阅提交的信心。她表示，一些资助机构提供现金奖励：在2022年，开放科学中心向愿意为其研究发布注册报告的意识研究人员提供最高50,000美元的资金。 Sena表示，追踪这些干预措施对学术界边缘群体的影响非常重要。她表示，少数族裔学者更有可能签订一份固定的合同，所以他们没有多少回旋余地去接受可能对整体科学更好、但对个别科学家没有多大帮助的形式。 开放科学中心计划进行试验，随机分配研究人员使用标准出版模型或注册报告，以评估所产生出版物的严谨性、接受率和时间线。预计结果将在2027年公布。 并非所有减少出版偏见的努力都取得了成效。Nosek表示，其中一个很少奏效的尝试是设立专门发布零结果的期刊。这些努力本是出于良好意图，但往往未能奏效，因为这些期刊可能被视为未能在其他地方发表的研究。“它无法提供研究人员所需的激励，”他说道。 Payne曾是这些期刊之一《Experimental Results》的共同编辑，该期刊由剑桥大学出版社出版。她说，尽管得到了“剑桥的认可”，该期刊在仅三年后于2023年停刊。 还有一种越来越流行的自助出版零结果的方法：在预印本服务器上发布手稿。发布预印本可以提供在没有期刊提交压力下展示研究的机会。Pilakouta表示，这一选择对早期职业研究人员尤为有利。Goodman说，尽管如此，无论在哪里发布，撰写结果都需要时间，而在预印本服务器上发布不太可能为研究人员提供足够的激励，以证明花费时间的合理性。 零结果\n倡导者承认，并非所有返回零结果的研究都值得发表。Goodman 表示，他鼓励研究人员发布那些“具有信息性”的零和阴性结果，即那些设计严谨、挑战了先前结果并开辟了新研究方向的研究。 例如，长期以来有一种观点认为子宫是无菌的——即子宫和胎儿中不存在微生物。然而，自2010年以来，一系列研究发现胎盘中可能存在微生物污染，这一发现挑战了这一假设，并提出一些妊娠并发症可能与细菌有关。直到2019年，一项对537名女性胎盘样本的研究——迄今为止此类分析中样本数量最多的一项——才严格地显示了没有细菌信号的存在。这项研究为调查微生物群体稀少的组织提供了基准，这些组织因此可能导致假阳性结果，并表明细菌感染并不是妊娠问题的常见原因。 Blume 表示，即使数据结果不确定，也应当从中提取有价值的见解。例如，在2022年，她发现尽管人工光抑制了激素褪黑素，但这并不等同于睡眠质量的变化。她指出，褪黑素不一定能作为睡眠质量的替代指标，这一发现可能为该研究的发表提供了重要依据。 Goodman预测，只要研究人员仍然渴望在顶级期刊上发表文章，出版偏倚就不会消失。然而，他对过去十年的进展感到惊讶：即便在五或十年前，顶级期刊承诺接受所有严格的研究，无论结果如何，这在当时都 …","date":1728518400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728518400,"objectID":"5de818d317d8da4dd649b46d48228aae","permalink":"https://terryzang.github.io/event/opentransfer/2024%E9%9B%B6%E7%BB%93%E6%9E%9C/","publishdate":"2024-10-10T00:00:00Z","relpermalink":"/event/opentransfer/2024%E9%9B%B6%E7%BB%93%E6%9E%9C/","section":"event","summary":"研究人员已经尝试了各种策略，以增加文献对阴性结果的收录。《Nature》对此进行了调查，探讨这些策略是否真正奏效。","tags":["OF"],"title":"翻译 | 如何让零结果的研究获得应有的关注","type":"event"},{"authors":["OpenMinds Team"],"categories":null,"content":"","date":1728432000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728432000,"objectID":"f6b64b22f379099f8a0e24ac77503f6f","permalink":"https://terryzang.github.io/event/openmind/2024_3.10/","publishdate":"2024-10-09T00:00:00Z","relpermalink":"/event/openmind/2024_3.10/","section":"event","summary":"Kruschke, J. K., \u0026 Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin \u0026 Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4","tags":["OM"],"title":"OpenMinds 3.0 | 第10期：频率论 vs. 贝叶斯统计","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":"开放与可重复性研究培训框架（Framework for Open and Reproducible Research Training, FORRT）是一项教育计划，旨在通过教学改革与元科学研究，推动研究的透明性、可重复性、严谨性和伦理。FORRT 提供教育基础设施与教学资源，帮助人们更好地理解开放与可重复性科学对教学的深远影响及其带来的挑战（如课程改革、认识论不确定性、教育方法）。同时，FORRT 倡导开放并正式认可这些教学与指导材料，帮助那些因教育资源匮乏而处于不利地位的群体获得更多学习与探索的机会。\n本期我们需要翻译和校对的是FORRT开放社区的开放学术术语表（Glossary of Open Scholarship Terms）。欢迎有热情、有能力的小伙伴一起加入我们，使用OpenTransfer团队开发的自动翻译工具进行翻译，并完成对翻译的人工校对工作。\n想了解更多关于FORRT的信息，请访问其官网：https://forrt.org/\nFORRT术语表翻译项目 在过去的十年里，开放科学（Open Science）运动引入了许多新的研究实践，旨在增强研究的透明性和严谨性。然而，随着开放科学相关术语和概念的不断增加，无论是初学者还是有经验的研究人员都感到难免感到困惑。为了帮助不同领域的研究者们，更加顺畅地参与开放科学的讨论，改进有关开放科学的指导与教学工作，FORRT发起了“术语表项目”，通过专门创建一个术语表来厘清与开放科学相关的术语，减少研究讨论中产生的理解隔阂，促进科学社区更有效地沟通。","date":1728345600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728345600,"objectID":"7fcfd0fc161627b7f9370422560802ec","permalink":"https://terryzang.github.io/news/2024-10-recruittranslators/","publishdate":"2024-10-08T00:00:00Z","relpermalink":"/news/2024-10-recruittranslators/","section":"news","summary":"开放与可重复性研究培训框架（Framework for Open and Reproducible Research Training, FORRT）是一项教育计划，旨在通过教学改革与元科学研究，推动研究的透明性、可重复性、严谨性和伦理。FORRT 提供教育基础设施与教学资源，帮助人们更好地理解开放与可重复性科学对教学的深远影响及其带来的挑战（如课程改革、认识论不确定性、教育方法）。同时，FORRT 倡导开放并正式认可这些教学与指导材料，帮助那些因教育资源匮乏而处于不利地位的群体获得更多学习与探索的机会。\n","tags":null,"title":"翻译校对招募 | FORRT开放学术术语表","type":"news"},{"authors":["OpenMinds Team"],"categories":null,"content":"报告人:\n陈书园（中科院心理研究所） 主持人:\n李淼（博士）Université de Lille，France ","date":1727035200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727035200,"objectID":"a33a8391b3cb215c07a349eeb54f6baf","permalink":"https://terryzang.github.io/event/openmind/2024_3.9/","publishdate":"2025-06-05T00:00:00Z","relpermalink":"/event/openmind/2024_3.9/","section":"event","summary":"Lakens, D. (2022). Sample size justification. Collabra: Psychology, 8(1), Article 33267. https://doi.org/10.1525/collabra.33267","tags":["OM"],"title":"OpenMinds 3.0 | 第9期：样本量规划","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":" 原文信息Lin, Z. (2024). How to write effective prompts for large language models. Nature Human Behaviour, 8(4), 611-615. https://doi.org/10.1038/s41562-024-01847-2\n译者/校对者列表OpenTransfer 自动翻译工作流程；刘若婷\n摘要随着大型语言模型在研究领域的广泛应用，有效使用大型语言模型正变得越来越重要。本文提供了一份实用指南，旨在帮助读者了解 大型语言模型的能力和局限性，并提供 编写结构合理的提示词的策略，从这些人工智能工具中获取最大效用。 正文 大型语言模型（LLMs）使用深度学习，来生成类似人类的文本以回应用户的查询，即“提示”（方框 1 提供了术语表，方框 2 提供了大型语言模型的入门知识）。深度学习是人工智能（AI）的一个分支，模仿人脑的神经网络。与依赖预定算法的传统软件不同， 大型语言模型能够解释自然语言命令，擅长从简单的句子补全到复杂的问题解决等各种任务，因此具有用户友好性和多功能性。在很短的时间内，大型语言模型已成为技术领域无处不在的存在，并且现已渗透到各个学科。它们迅速成为专业人士和学术研究人员在写作、编码和可视化方面不可或缺的工具。表 1 对主要的大型语言模型进行了比较。\n方框 1：术语表\n应用程序编程接口（application programming interface, API）：软件实体相互通信的一套规则。\n人工智能（artificial intelligence, AI）：在机器中模拟人类智能。\n偏差（biases）：机器学习模型中的偏见，源自训练数据。\n思维链提示（chain of thought prompting）：通过添加“让我们一步一步思考”等特定指令来提高模型推理能力的一种技术。\n上下文窗口或长度（context window or length）：模型可从对话历史中考虑的最大标记数。\n深度学习（deep learning）：人工智能的一个子领域，模仿人脑的神经网络来分析数据。\n分隔符（delimiters）：用于指示大型语言模型应该处理的某些数据或文本的开始或结束的符号或字符。\n幻觉（hallucination）：由大型语言模型生成的不正确或误导性语句。\n大型语言模型（large language models, LLMs）：在大量数据集上训练的机器学习模型，用于执行基于语言的任务。\n神经网络（neural networks）：受人脑启发的计算模型，用于机器学习算法解决复杂问题。\n参数（parameter）：可调整的权重，代表神经网络中人工神经元之间的连接强度。\n提示（prompt）：触发大型语言模型响应的用户查询或指令。\n提示工程（prompt engineering）：制作与大型语言模型交互的有效提示的艺术和科学。\n提示注入（prompt injection）：在提示中嵌入恶意指令，使模型执行非预期操作。\n人类反馈强化学习（reinforcement learning from human feedback, RLHF）：一种机器学习类型，其中模型根据人类评估者提供的实时反馈来学习决策。\n自注意力（self-attention）：转换器中的一种机制，用于评估输入文本不同片段的相关性。\n标记（token）：由大型语言模型处理的文本单位。\n转换器（transformers）：一种深度学习架构，旨在处理顺序数 据。\n方框 2：理解和使用大型语言模型\n开发人员首先使用深度学习训练大型语言模型。他们使用一种称为 转换器（transformers）的深度学习架构，该架构专门用于处理顺序数据。转换器的一个主要特点是 自注意力（self-attention），这种机制使模型能够评估输入文本中不同片段的相关性。通过这一过程，模型可以从包括网页、学术文章和书籍在内的大量数据集中“学习”。\n转换器将文本分解成更小的单位，称为 标记（token），这些标记可以小到一个字符，也可以大到一个单词。它们将这些标记转换成数值，作为模型的输入。在模型内部，有大量可调整的权重（通常称为 参数）。这些参数代表模型神经网络架构中人工神经元之间的连接强度。初始训练会对这些参数进行微调，以捕捉复杂的语言模式。由于在训练中使用了大量语言数据集，这些模型生成的文本与人类语言非常相似。最近，大型语言模型的训练已扩展到图像、视频和音频（这些模型有时被称为 大型多模态模型或 多模态语言模型）。\n经过初步训练后，大型语言模型会通过 人工反馈进一步完善。评估人员根据模型输出的准确性和相关性，对模型的反应提供实时反馈。这被称为 强化学习，因为大型语言模型会根据正面或负面反馈调整其参数。这意味着该模型将更加符合人类的价值观和期望。\n自 2017 年发布转换器架构以来，一些领先的大型语言模型已经可以通过基于网络的对话界面进行访问：表 1 对四种领先的大型语言模型进行了比较。对于那些寻求更灵活集成的人来说，应用编程接口（API）访问通常是可用的，这使用户能够向大型语言模型提供商的服务器发送 HTTP 请求，将模型纳入各种应用程序和服务（如创意写作平台或翻译服务）。使用 API 还可以对模型进行更多配置，例如通过设置温度参数来调整响应的随机性。有些提供商需要订阅或采用按使用付费的模式。\n在选择大型语言模型时，请考虑你需要模型完成的具体任务、模型在你所在地区的可用性以及你的个人偏好（表 1）。通过在不同任务中尝试使用不同的大型语言模型并比较其输出结果来建立直觉。由于大型语言模型在不断改进，因此需要随时关注发布说明和新功能。\n表 1 截至2024年2月17日的主要大型语言模型比较 为什么需要提示词？ 与大型语言模型的互动看似简单：只需输入问题，就能立即得到答案！然而，事实证明，有效地使用这些模型比最初看起来更加复杂和细致入微。这极大地限制了大型语言模型的实用性，因为它们的输出质量直接与提供的提示词质量相关——这一点在当前关于大型语言模型的实用性和能力的讨论中经常被忽视。 一个精心制作的提示词可以导致精确、准确和相关的回答，从而最大限度地提高模型的性能。反之，结构不良的提示词可能会导致模糊、不正确或不相关的回答。\n这种局限性在很大程度上源于大型语言模型的固有性质。尽管大型语言模型拥有复杂的算法和大量的训练数据（包括网页、维基百科文章、社交媒体帖子、学术文章、书籍和教学数据等材料），但它们只是数学模型，缺乏对世界的理解。这些工具旨在预测文本的可能性，而不是生成真相。它们通过利用训练数据中的模式识别， 使用统计可能性来预测文本。生成的文本类型在很大程度上取决于训练数据中的文本模式。此外，由于每个标记预测都会影响后续标记预测， 回复初期的失误可能会导致一连串的错误。因此，一个结构良好的提示词不仅可以提高每个标记被准确预测的可能性，而且还能将错误的复合效应降至最低。促使提示词变得重要的另一个关键因素是大型语言模型的 上下文学习能力。这种能力使模型能够临时适应所收到的提示词，从而使这些提示成为 传递语境信息的关键。\n因此，掌握制定有效提示词的艺术和科学（有时也被称为 “提示工程”），对于充分利用大型语言模型的能力至关重要。要达到最佳效果，需要结合领域特定的知识、对模型的理解和技能，而这些都必须通过学习和经验来磨炼。因此，首要建议是 多与模型互动。我们与模型的互动越多，就能更好地理解其细微差别，并了解如何更好地利用它们来满足我们的需求。本文概述了 可操作的策略和规则及其原理，为掌握这一技能奠定基础（见表 2）。\n表 2 提示词策略和示例 提示词策略和示例 1. 引导模型找到解决方案 大型语言模型缺乏语义理解，这使得它们难以在训练之外进行泛化。然而，它们庞大的参数设置赋予了它们一个巨大的后备数据（“记忆”），这些数据来自于它们的 训练数据（“长期记忆”）以及 提示词和交互历史（“工作记忆”）（见表 1 中的“上下文窗口”）。这种有限的泛化能力与强大的记忆能力相结合，使大型语言模型能够在 将复杂任务分解为更小的任务和步骤时有效地处理这些任务。\n例如，与其使用“将文本翻译成中文”这样宽泛的命令，不如将其分解为两个步骤：“首先按字面意思翻译，以保留原意，然后根据中文语言习惯完善译文”。同样，与其直接要求写一篇 1000 字的文章，不如将任务分解为若干子任务，并根据具体指令精心设计引言、结论和中心论点。\n清晰的逐步指令可以减少模糊性和不确定性，从而产生更准确的回应。通过 将广泛的任务简化为较小的、连续的组件，这种策略能够有效利用大型语言模型的强大记忆能力，同时通过结构化的指导弥补其有限的抽象能力。\n2. 添加相关背景\n大型语言模型拥有比人类大得多的“工作记忆”。因此，为了获得细致入微、上下文准确的回复， 提供相关的上下文作为输入至关重要。一个框架合理的提示词应该：\n· 嵌入具体内容。将具体细节作为查询的根基，引导大型语言模型做出更准确、更相关的解释。因此，与其要求它起草一封普通的求职信，不如向它提供具体的招聘广告和你的简历，以增加相关背景。\n· 优先考虑证据。将你的互动建立在相关的事实信息基础上。与其向模型询问获得永恒幸福的最佳方法，不如向它提供经过同行评审的研究报告，并根据这些研究结果向它提问。\n这样做的目的不是向大型语言模型灌输一般知识，而是让它了解与你的提问相关的一些特性。当提示词充满相关细节时，大型语言模型会生成更有洞察力、更细致入微的回答。\n3. 指令要明确\n要想得到自己喜欢的饮料，你不会随便走进一家咖啡店，然后说“请给我一杯咖啡！”。也不要指望大型语言模型能读懂你的心思。虽然让大型语言模型猜中你的意图甚至超出你的期望会让你感到高兴，但不准确的请求可能会导致大型语言模型偏离目标的回应。因此，指令清晰是关键。\n了减少模型预测的不确定性， 请明确说明你想要什么。与“修改文本”相比，你可以通过考虑想要的文体方式、目标受众以及是否有特定的侧重点（如清晰或简洁），来使用更明确的指令。因此，更具体的指令可能是“充当顶级期刊的编辑，提高文本的清晰度和流畅性”。\n再比如，与其征求对名称的建议，不如通过添加限制条件来更明确：“名称必须以动词开头，隐含的主语/行为者是用户”。尽量明确地说明任务、任务目标、希望强调的重点和任何限制条件。含糊的请求会导致含糊的回应，而明确的指令则有助于：\n·尽量减少指令和要处理文本的模糊性（例如，使用特定标签、字符或符号等分隔符）。\n·使大型语言模型的能力集中于你的特定需求。\n·提供判断模型准确性的明确标准。\n虽然大型语言模型是为会话精炼而设计的，但明确的指令可以通过事先声明你的目标来简化流程。你可以通过 阐明自己的目的和限制条件来引导对话。同时，在目标尚未完全确定的情况下，要避免过度具体化，因为这可能会导致错误的路径，或错过意想不到的、可能更好的回应。\n4. 要求提供大量选项\n大型语言模型的一个特殊优势在于其巨大的“长期记忆”。为了利用大型语言模型的这一潜力，你可以 要求其提供一系列选项，而不是单一的建议。例如，你可以要求用三个类比来解释一个概念，用五个想法来开始介绍，用十个替代方案来替换最后一段，或者用二十个名称来命名一个功能——让模型为你提供思考的食粮，然后从中进行选择。除了要求提供多个选项，你还可以 多次使用同一提示词重新生成响应。通过重新生成响应，你可以增加结果的多样性，并提升其整体质量。以下是要求提供多个选项和重新生成响应的几个优势：\n·鼓励模型探索多种可能性，从而提升输出的创造性和多样性。\n·为你提供更全面的选择，最大限度地减少接受次优或有偏见建议的风险。\n·促进迭代优化。\n大型语言模型是多才多艺的创意伙伴：从多个角度提供丰富的备选方案，能够丰富你的决策过程。多样化的选择能释放最大效益。\n5. 指定角色\n庞大的训练数据集意味着大型语言模型能够 模拟各种角色，提供专门的反馈或独特的视角。你可以考虑让模型进行角色扮演，而不是要求它提供一般的建议或信息：例如，让它扮演 …","date":1726617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726617600,"objectID":"fb1462306099ccd1e529b1e0076571f7","permalink":"https://terryzang.github.io/event/opentransfer/2024llm/","publishdate":"2024-09-18T00:00:00Z","relpermalink":"/event/opentransfer/2024llm/","section":"event","summary":"随着大型语言模型在研究领域的广泛应用，有效使用大型语言模型正变得越来越重要。本文提供了一份实用指南，旨在帮助读者了解大型语言模型的能力和局限性，并提供编写结构合理的提示词的策略，从这些人工智能工具中获取最大效用。","tags":["OF"],"title":"翻译 | 如何编写有效的大型语言模型提示词","type":"event"},{"authors":["OpenMinds Team"],"categories":null,"content":"","date":1722988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722988800,"objectID":"10dddb8b63ad62d9ebc8ab9c4d744431","permalink":"https://terryzang.github.io/event/openmind/2024_3.8/","publishdate":"2024-08-07T00:00:00Z","relpermalink":"/event/openmind/2024_3.8/","section":"event","summary":"Button, K. S., Ioannidis, J. P., Mokrysz, C., Nosek, B. A., Flint, J., Robinson, E. S., \u0026 Munafò, M. R. (2013). Power failure: why small sample size undermines the reliability of neuroscience. Nature Reviews Neuroscience, 14(5), 365–376. https://doi.org/10.1038/nrn3475","tags":["OM"],"title":"OpenMinds 3.0 | 第8期：统计检验力","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":" 原文信息\nMorey, R. D., Hoekstra, R., Rouder, J. N., Lee, M. D., \u0026amp; Wagenmakers, E.-J. (2016). The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin \u0026amp; Review, 23(1), 103–123. https://doi.org/10.3758/s13423-015-0947-8\n译者/校对者列表\nOpenTransfer 自动翻译工作流程；陈梁杰（北京大学）；温秀娟（广州医科大学）；刘若婷\n本文word版本请见：https://osf.io/fajrd 本文约22997字，全部阅读结束大约需要半小时以上，请合理规划阅读时长。 摘要 区间估计是一种对包含抽样不确定性的参数进行估计的方法，它长期以来被认为是统计分析的关键组成部分。区间估计的方法多种多样，但最流行的是置信区间（confidence intervals, CIs），即在重复抽样中以某个已知比率包含参数真值的区间。研究者通常认为，置信区间的宽度反映估计的精确度；置信区间指明哪些参数值更可能是真值或更加合理；区间的置信水平（例如，95%）表示真值在该区间内的可能性。然而，本文借助多个实例展示了置信区间并不一定具备这些属性中的任何一个，且这些误解会导致不合理或随意的推断。因此，我们敬告不要依赖于置信区间理论来说明区间估计的合理性，并建议使用其他区间估计的理论。 关键词：贝叶斯推理与参数估计，贝叶斯统计学，统计推断，统计 正文 “你一直在使用那个词。我不认为它意味着你认为它意味着的那样。” —— Inigo Montoya，《公主新娘》（1987） 在过去的百年里，统计学经历了飞速的发展，数据推断方法激增。这些方法在其哲学基础、解决问题的方式，以及实际应用的频繁程度等方面，呈现出广泛的差异。其中，备受欢迎且广泛应用的一类方法是区间估计方法。尽管这些方法在哲学基础和计算方式上有所不同，但它们共同点在于：能够提供一系列可能的参数值，而非单一值，来反映测量或抽样过程中的不确定性。 在诸多区间估计方法中，置信区间（CI）尤为受到青睐。几乎所有基础统计学教材都会介绍置信区间；众多知名期刊的方法论指南也推荐甚至要求使用置信区间（如，Psychonomics Society, 2012; Wilkinson \u0026amp; the Task Force on Statistical Inference, 1999）；并且它们构成了方法学改革方案的基础（Cumming, 2014; Loftus, 1996）。在当前的方法学改革中，正确理解置信区间理论允许和不允许的推断类型，对于确定未来科学研究的方向至关重要。 本文认为，当前对置信区间的推崇往往基于一种非原则性的“民间理解”。接下来，本文将概述这种民间CI理论中的三大谬论，并在CI理论的哲学和历史背景下进行分析；通过一个改编自统计学文献的简明例子，展示CI理论与民间CI理论之间的差异；最后，在广泛支持与使用CI的方差分析和回归分析中，展示置信的常见谬误，并讨论CI理论与民间CI理论不一致的深层含义。 本文的核心主张是：不应像如今支持者所建议的那样使用置信区间，因为这种方法在置信区间理论中并未得到验证。他们所谓的CI的优势，并非源于置信区间理论；如果按照他们的建议使用CI，可能导致严重的误导性推断。在许多CI应用中，支持者实际上并未探讨其是否支持合理的推断。因此，我们认为，在最佳情况下（推断的合理性可以在CI理论之外证明），诉诸CI理论是不必要的；而在最糟糕的情况下（推断合理性不能被证明），这种使用是不明智的 置信区间的民间理解\n在科学实践中，经常需要对我们感兴趣的某些数值进行估计，并表达对这些估计的不确定性。例如，当需要估计正态总体的真实均值$μ$，通常会选择样本均值$x̄$作为估计值。一般来说，我们希望$x̄$能接近$μ$，这种接近程度取决于样本大小和样本中观察到的变异性。为了表达估计值的不确定性，通常会使用置信区间。 关于置信区间，所有人都同意的一个基本定义是：某参数（通常称为$\\theta$，可能是总体均值、中位数、方差、概率或任何其他未知量）的置信区间是由一个特定的重复抽样过程生成的区间，这个过程有固定概率包含该参数。例如，如果生成一个包含$\\theta$的区间的概率为0.5，则代表50%的置信区间；如果这个概率为0.95，则代表95%的置信区间。 定义1（置信区间）：参数$\\theta$的X%置信区间是由一个特定过程生成的区间$[L,U]$，在重复抽样中，这个过程有X%的概率包含$\\theta$的真值，且对$\\theta$的所有可能值都适用（Neyman, 1937）[1]。 置信区间的置信系数来源于生成它的过程。因此，区分置信程序（confidence procedure）和置信区间是有帮助的：X% 置信程序是在重复样本中生成包含$\\theta$的区间的过程，而置信区间是由这样的过程生成的特定区间。置信程序是一个随机过程；而置信区间是被观察并固定的。\n如何解释置信程序似乎很清晰：它是生成置信区间的过程，这些区间将在样本的固定比例中包含参数的真值。然而，当我们从数据中计算出一个具体的区间并必须对其进行解释时将是困难的。如何从我们对置信程序属性的了解转移到对某个观察到的置信区间的解释，这并不明显。\n教科书作者和置信区间的拥护者通过三个显著特点，巧妙地填补了理论与实践之间的鸿沟：（1）置信区间的置信系数被视为对区间包含参数的不确定性的衡量；（2）置信区间的宽度反映了对估计不确定性的评估；（3）这个区间被认为涵盖了参数的“可能”或“合理”取值范围。这些观点均涉及基于观测数据进行参数推断，即所谓的“后数据（post-data）”推断。\n例如，Masson和Loftus（2003）针对95%置信区间提出：“在没有其他信息的前提下，我们得到的置信区间有95%的概率包含总体均值。” 而Cumming（2014）则表述：“我们有95%的把握认为，我们的区间涵盖了[参数]，并且可以认为这个区间的上下限分别是[参数]可能的最大和最小值。”\n然而，这些关于置信区间的解释并不准确，它们似乎是对置信区间定义的自然但错误的推断。我们将其称为“基本置信谬误”（Fundamental Confidence Fallacy）。\n谬误1（基本置信谬误）：如果一个随机区间以X％的概率包含真值，那么特定观察到的区间包含真值的可能性或概率同样是X％；或者，我们可以对观察到的区间包含真值有X％的信心。 基本置信谬误的逻辑似乎是合理的：在给定样本的情况下，我们可以得到任意一个可能的置信区间。如果95%的可能的置信区间包含真值，那么在没有其他信息的情况下，似乎有理由说我们有95%的把握认为我们获得了一个包含真值的置信区间。然而，“置信区间”这一术语本身就暗示了这种谬误：在通常的语境中，“置信”这个词与可信性和信念的概念紧密相关。与“覆盖程序（coverage procedure）”这一更精确的术语相比，“置信区间”一词似乎助长了基本置信谬误。\n基本置信谬误的核心混淆在于：它将观察数据之前已知的信息——即置信区间无论如何都有固定的机会包含真值——与观察数据之后所获得的信息混为一谈。频率主义CI理论并未对某一特定观察到的置信区间包含真值的概率做出任何陈述；它要么是0（如果区间不包含参数），要么是1（如果区间确实包含了真值）。\n本文通过几个例子展示了计算区间之前和之后所知信息的不同。目前，我们提供一个简单的例子，称之为“微不足道的区间（trivial interval）”。假设要通过两个独立观测值$y_1$和$y_2$估计连续总体的均值。如果$y_1$大于$y_2$，我们构造一个包含所有实数的置信区间$(-∞,∞)$；如果不是，则构造一个空置信区间。前者保证包含真值，后者则不包含。在观察数据之前，任意一个抽样区间包含真均值的概率显然为50%。然而，在观察数据之后，我们便能确切知道区间是否包含真值。将50%的先验概率应用于我们已确切知道区间是否包含真值的后数据情况，这无疑是一种根本性的推理错误。\n事实上，事后概率评估并非置信区间理论的宣传要点。例如，Neyman （1937, p. 349）指出：“当一个样本已经抽取并给出了[置信区间]时，我们是否能说在这种特定情况下，[参数]的真值落在[限制]内的概率等于[X%]？答案显然是否定的。” 频率主义哲学家Mayo（1981）进一步阐释道：“[这种误解]似乎源于人们对于置信区间的期望——它们能提供某些本质上无法提供的东西，即对未知参数值位于特定区间内的概率、信念或支持程度的度量。”近期研究表明，这种谬误在研究人员中普遍存在，他们可能是习自教科书、教师和置信区间的倡导者（Hoekstra et al., 2014）。\n如果置信区间不能用于评估参数在特定范围内的确定性，那么它们到底有什么用途呢？置信区间的支持者经常声称，置信区间可用于评估参数的估计精度。这被视为使用置信程序而非零假设显著性测试的主要原因之一（如，Cumming \u0026amp; Finch, 2005; Cumming, 2014；Fidler \u0026amp; Loftus, 2009; Loftus, 1993, 1996）。例如，Cumming（2014, p. 10）指出：“长置信区间很快就会告诉我们，我们的实验效果是否不佳且仅能提供不精确的估计。”Young和Lewis（1997, p. 309）指出：“了解点估计如何精确表示两组之间的真实差异非常重要。置信区间的宽度为我们提供了关于点估计精度的信息。”这便是置信区间的第二个谬误，即“精度谬误（precision fallacy）”。\n谬误2（精度谬误）：置信区间的宽度反映了我们对参数的了解精度。窄置信区间意味着精确的了解，而宽置信区间则代表不精确的了解。 然而，估计的精度与置信区间的大小并没有必然联系。设想两位研究人员——一位资深研究员和一位博士生——正在分析一项包含50名参与者的实验数据。为了让博士生有所学习，资深研究员决定随机将参与者分为两组，每组25人，他们分别分析其中一组数据。在随后的会议上，他们分享了各自计算出的均值的Student’s $t$置信区间。博士生的95%置信区间是52±2，而资深研究员的是53±4。资深研究员指出，他们的结果基本一致，可以将两个点估计的等权重加权平均值52.5作为真实均值的总估计。\n博士生却提出，她的置信区间更窄，因此应该给予更多的权重。她认为自己的估计更精确，应更为重要。她的导师则指出这是错误的，因为不均等加权两个均值得出的估计会与分析完整数据集得出的估计不同，而后者一定是52.5。博士生的误区在于，她错误地认为置信区间直接反映了后数据的精度。稍后，我们将通过几个例子说明，置信区间的宽度与参数估计的不确定性在某些情况下成反比，而在另一些情况下则没有任何关系。\n我们不能将观察到的置信区间解释为以某种概率包含真值；我们也不能将置信区间解释为它能指示我们估计的精度。置信区间的第三种常见谬误是：如Loftus（1996）所述，置信区间提供了一个“所观察到的均值模式应如何认真地被视为反映总体均值的潜在模式”的指标。当置信区间用于检验理论（Velicer et al., 2008）或支持零假设（即实际上为零）的论证时（Loftus, 1996），便采用了这种逻辑。我们将这种误解称为“似然性谬误（likelihood fallacy）”。\n谬误3（似然性谬误）：置信区间包含了参数的可能值。区间内的值比区间外的值更有可能出现。这种谬误以多种形式存在，有时会涉及参数信念的合理性、可信度或可解释性的评估。 即便一个置信程序可能具有包含真值的固定平均概率，但在任何给定样本中，它是否包含“合理”的值则是另一个问题。正如我们即将展示的，即使是从置信区间理论角度看来“好的”的置信区间，也可能排除几乎所有合理的值，并且可能为空或无限 …","date":1722988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722988800,"objectID":"cb98ad5d4d10db18d45521c70f513b98","permalink":"https://terryzang.github.io/event/opentransfer/2024%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4/","publishdate":"2024-08-07T00:00:00Z","relpermalink":"/event/opentransfer/2024%E7%BD%AE%E4%BF%A1%E5%8C%BA%E9%97%B4/","section":"event","summary":"区间估计是一种对包含抽样不确定性的参数进行估计的方法，它长期以来被认为是统计分析的关键组成部分。区间估计的方法多种多样，但最流行的是置信区间（confidence intervals, CIs），即在重复抽样中以某个已知比率包含参数真值的区间。研究者通常认为，置信区间的宽度反映估计的精确度；置信区间指明哪些参数值更可能是真值或更加合理；区间的置信水平（例如，95%）表示真值在该区间内的可能性。然而，本文借助多个实例展示了置信区间并不一定具备这些属性中的任何一个，且这些误解会导致不合理或随意的推断。因此，我们敬告不要依赖于置信区间理论来说明区间估计的合理性，并建议使用其他区间估计的理论。","tags":["OF"],"title":"翻译 | 将信心放在置信区间的谬误","type":"event"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6e0e6e864df1b2608fdb8b11af96ec60","permalink":"https://terryzang.github.io/about/cosn/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/about/cosn/","section":"about","summary":"","tags":null,"title":"About COSN","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"7989e3874f54ade2a8fadc77ed28a4ed","permalink":"https://terryzang.github.io/about/duty/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/about/duty/","section":"about","summary":"","tags":null,"title":"Committee Duty","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"8f36f143408b8146ec3f780d6df4b0f4","permalink":"https://terryzang.github.io/about/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/about/people/","section":"about","summary":"","tags":null,"title":"People","type":"landing"},{"authors":["OpenTransfer Team"],"categories":null,"content":" 原文信息\nColes, N. A., Hamlin, J. K., Sullivan, L. L., Parker, T. H., \u0026amp; Altschul, D. (2022). Build up big-team science. Nature, 601(7894), 505–507. https://doi.org/10.1038/d41586-022-00150-2\n译者\n刘逸康（南京师范大学心理学院）\n校对\n张晗（新加坡 A*STAR）；胡传鹏（南京师范大学心理学院） 本译文下载地址：https://osf.io/2ce8a/\n本文要点 研究人员正在创建“草根”合作网络，以尝试去解决灵长类动物研究等方面的难题，但他们亟需资金和其他支持。 正文内容 如果不重新定义研究的方式，我们是否根本无法回答科学上一些最重要的问题？这个拷问激励一批研究者创建了ManyBabies联盟（ManyBabies Consortium）。ManyBabies联盟是一个由来自200多个机构的约450名科研合作者组成的“草根”网络（grass-roots network），他们集中资源开展了多项关于婴幼儿发育的大规模研究（massive study）1。人类婴幼儿也许是地球上最强大的学习机器——了解他们的学习机制对人工智能、公共政策、教育等具有启示意义。然而，现有的科研模式使得全面了解婴幼儿的学习机制比较困难。 举一个简单的例子：什么东西能吸引婴幼儿的注意力？比如，一只兔子？一个婴幼儿会注意到兔子的概率取决于兔子如何呈现（例如，由母亲或陌生人呈现给婴幼儿）、婴幼儿先前与哺乳动物接触的经验、与兔子同时呈现的其他物品等因素。要有效地回答这个问题，需要几十种实验条件和几百个婴幼儿。但大多数婴幼儿研究项目往往由单个实验室及其不断流转的博士生来实施，因此上述的每种实验条件一般难以收集到25个婴幼儿数据2。 但是，如果研究者们互相合作，同时在多个实验室间协同工作，情况会如何呢？这样的团队联盟也许能够解决单个实验室无法尝试解决的问题。在一项概念验证研究中，ManyBabies联盟利用口耳相传、社交媒体和电子邮件等方式，组成了一个由69个实验室组成的团队，以验证世界各地的婴幼儿是否更喜欢\u0026#34;儿向语(baby talk)\u0026#34;（参考联合国儿童基金会翻译为“儿向语”[1]，指的是许多文化中的成年人对婴幼儿使用的一种高声调、唱腔的说话方式）。来自16个国家的2329名婴幼儿的数据提供了一个非常肯定的回答，并且婴幼儿甚至更喜欢非母语的“儿向语”3。谷歌学术显示，这项领域内规模最大的研究在其发表后的一年内就被引用了100多次。 ManyBabies联盟并不是个别现象。它是更广泛的“草根”大团队科学运动的一部分：分散在世界各地、不同机构的大量研究人员自发组织起来，汇集才智、集中资源，追求同一个目标4。除了ManyBabies联盟，研究者们还合作创建了心理科学加速器项目 (Psychological Science Accelerator)（约1200名研究人员参与）5，全球草原波动与资源网络（Disturbance and Resources Across Global Grasslands network，DRAGNet；约100名研究人员；https://dragnetglobal.weebly.com）和ManyPrimates项目（包括约150名研究人员）6。这些自发组织的研究团体汇集资源，分别在心理学、生态学和灵长类研究方面开展了多项大规模研究。它们的合作模式类似于人类基因组计划和欧洲核子研究中心（CERN，位于瑞士日内瓦附近的欧洲粒子物理实验室），但它们在成立时没有正式的资金资助机制或发达的基础科研设施。 我们发现，尽管“草根”大团队科学能够产生难以获得的知识，但是在可持续性方面却面临着不少困难。 [1] https://www.unicef.cn/parenting-site/how-talk-your-baby\n大团队科学的例子\n大团队的科研工作者们以多种多样的方式聚集在一起，尝试解决科学中的难题，从土壤样本到癌症生物学。 困难1：如何奖励团队成员 美国田纳西州孟菲斯大学的历史学家Michele Grigsby Coffey将学术描述为“一场利己的运动”，在这项运动中，研究人员“因自我陶醉而得到奖励”，并且“鼓励以牺牲他人利益为代价来优先考虑自己”7。然而，大团队科学是一项团体运动，它常常要求研究人员将研究发现置于自己的利益之上。例如，第一个ManyPrimates研究考察了40多种灵长类动物的工作记忆能力，即测试它们是否能在短时延迟后记住食物隐藏的位置8。作为该研究的共同作者之一，D.A.估计他为这个项目投入了大约200个小时。但是在所发表的论文中，ManyPrimates联盟被列为第一作者，通讯作者的电子邮箱是一个共享的邮箱，在按字母排序的作者名单中D.A.只是79人之一。这样的文章署名方式突出了团队的成就而不是任何个人。 追求大团队科学的理想是相对无私的，但当前学术界的规则作为这场利己的运动的裁判员，它会对这样的理想做出惩罚。例如，当作者之一的N.A.C.在博士后研究期间被提名领导心理科学加速器项目时，一位善意的指导教授告诉他，他将十分胜任这项工作，不过这个项目将\u0026#34;扼杀你获得终身教职的机会\u0026#34;。本稿件中资历较深的共同作者（J.K.H.、L.L.S.和T.H.P.）也向年轻同事提出过类似的警告。例如，当招聘委员会的成员看到求职者简历中所列的几篇论文，求职者的名字在一长串作者名单的中间时，他们会大吃一惊。学术这场利己的运动奖励的是明星而不是那些关键的配角。事实上，当本文的一名作者兴奋地将大团队合作取得的重大进展向部门主管分享时，得到的回应却是“很好，但是要确保你自己的研究团队要有成果。” 学术界可以通过奖励那些为团队工作做出巨大贡献的研究人员来改变游戏规则。否则，团队将被迫寻找其他方式来增加收益或降低参与成本。例如，项目负责人可以资助合作者，正如美国国防部高级研究计划局（www.cos.io/score）支持的合作项目，这项合作项目设计出可以预测社会和行为科学研究结果可重复性的工具。然而，这种做法的问题是：资源较少的研究人员无法领导大团队工作。作为一个替代方案，一些合作提供了非经济性的福利。例如，DRAGNet和Nutrient Network都为参与合作的研究人员提供了访问整个项目数据库的独家权限。然而，这些政策却背离了使科学更加开放和包容的目标。通过招募更多的研究人员来分担费用，可以达到降低成本的目的，但这使得组织协调工作变得更加困难。 困难2：多样性（与代表性） 大团队科学研究的一个很大的潜在优势就是增加了被试（participant/ subject，即参加研究的志愿者，心理学中翻译为“被试”，也有翻译为“受试者”，后文统一翻译为 “被试”）、研究者和研究问题的多样性。但我们注意到一个令人担忧的趋势：基础科研设施中原先存在的不平等似乎在大团队科学中继续延续。 2021年的一项分析指出，前殖民地国家的研究人员往往无法获得参与大团队科学所需的实验室空间和资金9。这并不奇怪，这些不平等似乎也影响了谁来领导这些工作。在本次调研中，没有一个行为科学大团队项目是由发展中国家的研究人员领导的。此外，ManyBabies、心理科学加速器、营养素网络和DRAGNet的联合管理和指导委员会中，只有4名（委员会共32人）成员来自北美或西欧之外（委员会成员的来源地：美国17人，加拿大5人，西欧6人，肯尼亚1人，阿根廷1人，澳大利亚1人和印度1人）。 大团队科学理应找到改变上述趋势的方法。例如，心理科学加速器利用捐款向代表性不足的地区的研究人员发放参与补助。ManyBabies联盟推出了其第一项研究的扩展：在瑞士苏黎世的Jacobs基金会的支持下，ManyBabies联盟为非洲的数据收集提供资金、培训和支持。DRAGNet通过让资源匮乏的机构将种子样本运送到资源较好的机构进行处理，最大限度地降低了成本。ManyPrimates团队通过参加代表性不足的地区的学术会议，同时用西班牙语或法语等语言的出版物向当地的学术共同体传播知识，促进了该项目与代表性不足的南半球地区的联系。 研究人员也可以通过培训和支持代表性不足地区的研究人员来尝试缩小基础科研设施的差距。例如，在心理科学加速器的几名成员支持的大力支持下，一名来自尼日利亚的博士生领导了一个大团队项目，在非洲各地区调查人们如何评价道德过失10。 困难3：资金和可持续性 尽管大团队项目有公认的产出，成员们都在不断地努力以维持大团队的持续，这些项目的建立往往只需要很少的资金。但是如果没有资金支持，它们还是很难维持。大团队科学需要资金来留住那些知道如何开展“下一代”大规模协同研究的科研人员，需要资金用于维护日益复杂的工作流程管理工具，也需要资金用于支持那些资源不足的研究人员。 例如，第一项心理科学加速器研究考察了世界各地的人们是如何根据面部外观来判断他人的11。该项目由241个合作者参与，采集了41个国家11570名被试数据。原则上，这项研究需要花费数十万美元。假设数据收集过程，每名被试研究助理的报酬是30分钟5美元，那么整个研究的成本会超过115,000美元。如果考虑到项目管理的劳动力成本，花费会更高，这其中包括获得150多份伦理批准文件，将研究材料翻译成23种语言，以及开发研究工具来跟踪进展并验证来自世界各地实验室的数据（见go.nature.com/3jcsutx）。实际上，由于数百名合作者捐赠了他们的时间和资源以弥补差额，该项目正式运作的费用不到2000美元（见go.nature.com/3qstumf）。 靠微薄的捐款运行的研究工作既不可能持续，也难以扩大。这一事实在2020年初变得很明显，当时心理科学加速器收到了66份关于COVID-19新冠病毒肺炎大流行下的心理学全球研究项目的紧急提案。但是出于经济上的考虑，心理科学加速器不得不拒绝了大部分提案，只保留了三个提案。一个被拒绝的提案旨在减少谣言的传播：在分享新闻之前提醒人们考虑其准确性是否有助于减少新冠疫情时期的各种假新闻和谣言？现在，每当我们看到诸如“抗寄生虫药物可以预防新冠”、“孕妇不应该接种新冠疫苗”或“COVID-19疫苗含有微型芯片”之类的谣言时，就会痛苦地想起那项因缺乏资金而未能进行的研究提案。 为什么“草根”的大团队科学行动很难获得资金？政府和慈善资助者提供了各种理由。例如，大团队科学最终会因为学术界的利己规则而被证明是不可持续的；大团队科学在研究人员和研究问题方面仍然不够多样化；大团队科学的工作系统尚未建设好，无法处理有数百个合作者的提案，也无法处理向几十个研究机构发出资助请求。最令人受挫的一个理由是：目前大团队科学在没有得到政府和慈善资助的情况下也能运行（所以不用资助了）。 领导大团队科学运动有时感觉就像在没有绳索的情况下攀登世界上最高的山峰。我们已经瞥见了山峰，可以想象绝顶之上的风光，但我们缺乏装备和资源来攀登得更高。在学术机构和资助者提供早就该提供的支持之前，大团队科学未来的每一步都会变得愈加艰难。 参考文献 Byers-Heinlein, K. et al. Can. Psychol. Can. 61, 349–363 (2020).\nOakes, L. M. Infancy 22, 436–469 (2017).\nManyBabies Consortium. Adv. Methods Pract. Psychol. Sci. 3, 24–52 (2020).\nForscher, P. S. et al. Preprint at PsyArXiv https://doi.org/10.31234/osf.io/2mdxh (2020).\nMoshontz, H. et al. Adv. Methods Pract. Psychol. Sci. 1, 501–515 (2018).\nMany Primates et al. PLoS ONE …","date":1643328000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643328000,"objectID":"80530023008bfcfcb04729e3cc3a85de","permalink":"https://terryzang.github.io/event/opentransfer/2022%E5%A4%A7%E5%9B%A2%E9%98%9F/","publishdate":"2022-01-28T00:00:00Z","relpermalink":"/event/opentransfer/2022%E5%A4%A7%E5%9B%A2%E9%98%9F/","section":"event","summary":"研究人员正在创建“草根”合作网络，以尝试去解决灵长类动物研究等方面的难题，但他们亟需资金和其他支持。","tags":["OF"],"title":"翻译 | 建立大团队的科学","type":"event"},{"authors":["OpenMinds Team"],"categories":null,"content":"报告人:\n王海侠（暨南大学） 主持人:\n陈妍秀（中科院心理所） ","date":1641758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641758400,"objectID":"84e93806018c5fb5245171c260024fbb","permalink":"https://terryzang.github.io/event/openmind/2022_2.3/","publishdate":"2022-01-08T00:00:00Z","relpermalink":"/event/openmind/2022_2.3/","section":"event","summary":"Muthukrishna, M., \u0026 Henrich, J. (2019). A problem in theory. Nature Human Behaviour, 3(3), 221-229.","tags":["OM"],"title":"OpenMinds 2.0 | 第3期：可重复性危机背后的理论问题","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":"原标题：Bayesian Estimation of Signal Detection Models, Part 4\n原文地址：https://vuorre.netlify.app/post/2017/10/12/bayesian-estimation-of-signal-detection-theory-models-part-4/\n原作者：Matti. Vuorre\n译者：田宇浩 刘帅呈\n校对：胡传鹏 金海洋\n分层EVSDT模型 案例数据 为展示如何使用层级EVSDT模型对信号检测论结果进行贝叶斯估计，本文选用了一个包含48名被试的数据。其中每名被试均根据自身对呈现刺激的确信程度报告新刺激(或旧刺激)的评价等级，对刺激的新旧进行6点计分评级：1 =“呈现刺激肯定为新刺激”, …, 6 =“呈现刺激肯定为旧刺激” (Koen etal., 2013)。R语言的MPTinR包中包含该案例数据(Singmann, \u0026amp; Kellen, 2013)。\n在该实验中 (Koenet al., 2013)，被试完成学习阶段识记后在无干扰条件(全神贯注)或在干扰条件(执行一个额外任务)下完成再认测验阶段。我们这里关注在无干扰条件下被试判断的评级数据。我从该篇文章的附录中摘出了新旧项目判断的计数表如下所示(以确保我们使用了相同的数据)。\nisold 6 5 4 3 2 1 old2604634384389422309 new37935645487113351365 对于完整的R代码(包括数据的预处理)，请参阅这篇博客的源代码(https://github.com/mvuorre/vuorre.netlify.com/blob/master/content/post/2017-10-30-bayesian-estimation-of-signal-detection-theory-models-part-4.Rmd)。为简练起见，本篇博客中省略了一些不太重要的代码。\n模型语法 这是我们用于估计单个被试信号检测论模型的brms语法：\nuvsdt_m \u0026lt;-bf(y ~ isold, disc ~ 0 + isold) 上述语法是由以下7个参数组成的：在y[1]上的5个截距(在累计概率(cumulative probit)模型中又称为阈限(thresholds))；isold 对y的影响；和isold 对辨别参数disc[2]的影响。之所以存在5个截距(阈限)是因为存在6种反应类别。\n通过设定所有被试都拥有自己特定的上述参数(数据中的id变量)，我们将前面的代码扩展到了层级模型。\nuvsdt_h \u0026lt;-bf(y ~ isold + (isold |s| id), disc~ 0 + isold + (0 + isold |s| id)) 回想一下以前使用|s|来估计各种变量间相关的博客。与这些阈值相关的只有一个标准差。也就是说，这个模型假设被试所有的阈限相对于均值的变化是相似的。\n[1] 截距是自动被包含在模型中，但是截距也能通过添加1到这个公式的右侧来明确地被包含在模型中。\n[2] 0 + ...移除了这个模型的截距。 先验分布 我设置辨别力指标d’的先验为N(1, 3)(即均值为1，标准差为3的正态分布[3])，因为我知道被试的任务表现通常都很好。可能这个先验分布也受到了我阅读这篇文献的影响！我设置a的先验为N(0, 1)：这个参数通常来说是在-1/4左右，但是这里我忽略了这个信息。\n我设定被试间标准差的先验分布为 t(7, 0, .33)，这反映出我假设被试间应该存在中等程度的相似，但也允许存在更大的偏差(该先验分布表示自由度为7，平均数为0，标准差为0.33的t分布)。\nPrior \u0026lt;- c(prior(normal(1, 3), class = \u0026#34;b\u0026#34;, coef = \u0026#34;isold\u0026#34;), prior(normal(0, 1), class = \u0026#34;b\u0026#34;, coef = \u0026#34;isold\u0026#34;, dpar = \u0026#34;disc\u0026#34;), prior(student_t(7, 0, .33), class = \u0026#34;sd\u0026#34;), prior(student_t(7, 0, .33), class = \u0026#34;sd\u0026#34;, dpar = \u0026#34;disc\u0026#34;), prior(lkj(2), class = \u0026#34;cor\u0026#34;)) [3] 译者注。 估计并总结参数 我们可以像之前一样(参见本系列先前文章)估计这个模型。但请注意，这个模型的估计耗时相当长(注意我已经将默认的2000次迭代次数减少到了500次)。\nfit \u0026lt;- brm(uvsdt_h, family =cumulative(link=\u0026#34;probit\u0026#34;), data =d, prior =Prior, control= list(adapt_delta = .9), inits = 0, cores = 4, iter = 500, file =here::here(\u0026#34;static/data/sdtmodel4-1\u0026#34;)) 我们接着展示该模型的参数估计结果。请注意这里有效样本量偏小，并且Rhat说明从后验中提取更多的样本对我们更有利。实际应用的时候，我建议每个链条(chain)要超过500次迭代。\nsummary(fit) ## Family: cumulative ## Links: mu = probit; disc = log ## Formula: y ~ isold + (isold | s | id) ## disc ~ 0 + isold + (0 + isold | s | id) ## Data: d (Number of observations: 9502) ## Samples: 4chains, each with iter = 500; warmup = 250; thin = 1; ## total post-warmup samples = 1000 ## ## Group-LevelEffects: ## ~id (Number oflevels: 48) ## Estimate Est.Errorl-95% CI u-95% CI Eff.Sample ##sd(Intercept) 0.35 0.04 0.28 0.43 210 ## sd(isold) 0.79 0.10 0.62 1.01 321 ##sd(disc_isold) 0.46 0.05 0.38 0.55 319 ##cor(Intercept,isold) -0.47 0.12 -0.68 -0.22 121 ##cor(Intercept,disc_isold) 0.35 0.13 0.08 0.58 273 ##cor(isold,disc_isold) -0.76 0.07 -0.87 -0.61 455 ## Rhat ##sd(Intercept) 1.03 ## sd(isold) 1.00 ##sd(disc_isold) 1.01 ##cor(Intercept,isold) 1.03 ##cor(Intercept,disc_isold) 1.02 ##cor(isold,disc_isold) 1.00 ## ## Population-LevelEffects: ## Estimate Est.Error l-95% CI u-95%CI Eff.Sample Rhat ## Intercept[1] -0.60 0.05 -0.70 -0.49 200 1.00 ## Intercept[2] 0.20 0.05 0.09 0.30 197 1.00 ## Intercept[3] 0.69 0.05 0.60 0.80 203 1.00 ## Intercept[4] 1.04 0.05 0.94 1.14 212 1.01 ## Intercept[5] 1.49 0.05 1.39 1.59 230 1.00 ## isold 1.86 0.12 1.63 2.10 119 1.04 ## disc_isold -0.38 0.07 -0.52 -0.25 112 1.05 ## ## Samples weredrawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crudemeasure of effective sample size, and Rhat is the potential ## scale reductionfactor on split chains (at convergence, Rhat = 1). 让我们首先看一下“群体水平的效应(Group-Level Effects)”：“人均(average person)”isold的效应就是辨别力指标d’，它非常接近论文中所报告的结果(目测Koen et al. (2013)中的图3得到；这个d’在该论文中未被报告)。由于模型的参数化，disc_isold为−log(σsignal)=−a。这篇论文探讨了Vo=σsignal，因此我们将来自-a中的每个后验样本转换为符合Vo的后验分布样本。\nsamples \u0026lt;- posterior_samples(fit, \u0026#34;b_\u0026#34;) %\u0026gt;% mutate(Vo =exp(-b_disc_isold)) 我们由此可以对于模型中包括Vo在内的每个样本群体水平的效应绘制密度曲线(Gabry 2017) 。图1表明我们对于Vo的估计与论文报告的结果非常接近(Figure 3 in Koen et al. (2013)).\nlibrary(bayesplot) mcmc_areas(samples, point_est = \u0026#34;mean\u0026#34;, prob = .8) 图1:UVSDT模型中群体水平效应的后验分布的密度图。不同的参数标注在y轴上，而分布值在x轴上表示。垂直线为后验均值，阴影区域为80%可信区间。 异质性参数 尽管“群体水平估计”(或许更应称为“平均效应”)通常是研究中推断的主要目标，但它们并不是故事的全部，也不一定是所有故事中最有趣的部分。可以确定的是，当允许信号分布的标准差变化时，它通常大于1。但是这个参数在被试间的差异却很少有人关注。图2揭示了a的被试间异质性是相当大的：个体差异的标准差大概在0.5左右。\nsamples_h \u0026lt;- posterior_samples(fit, c(\u0026#34;sd_\u0026#34;, \u0026#34;cor_\u0026#34;)) mcmc_areas(samples_h, point_est = \u0026#34;mean\u0026#34;, prob = .8) 图2：UVSDT模型参数的标准偏差和相关参数的密度图。带有“ sd_id__”的参数是-id间的标准差，带有“ cor_id__”的参数是-id间的相关性。 图2还告诉我们，个体差异的辨别力指标d’和与a是相关的(‘cor_id__isold__disc_isold’)。我们可以通过同时绘制信号方差和辨别力指数d’的个体差异来进一步研究这种关系：\n图3:个体差异标准差(左)和辨别力指数d’(右)后验分布的脊线图。被试在y轴上的顺序是相同的，以此更好地展现两变量间的关系。 从图3的山脊线图(Wilke 2017)中可以看出，信号标准差(σsignal)越大的被试越倾向于有更大的辨别力指数d’：伴随着信号分布变异性的提高，被试再认的敏感性同样提高。图2的密度图还清楚地表明，我们并不确定哪些被试的(哪一个指标)是更大的，正如后验分布所展示的那样。图4所示的后验均值散点图是可视化这种关系的另一种方法。\n图4:个体特异性的辨别力指标和信号分布标准差的后验均值散点图。 总结 使用R的brms包( Bürkner2017)在贝叶斯框架下估计EVSDT和UVSDT模型既简单(相对而言)，又可以提供足够的信息。在这篇文章中，我们使用了很少的几行代码估计了一个层级非线性认知模型。以往有关此主题的文献(e.g. …","date":1615680000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615680000,"objectID":"352ba6f23b828a2d15043d71a0bc98e4","permalink":"https://terryzang.github.io/event/opentransfer/2021%E8%B4%9D%E5%8F%B6%E6%96%AF4/","publishdate":"2021-03-14T00:00:00Z","relpermalink":"/event/opentransfer/2021%E8%B4%9D%E5%8F%B6%E6%96%AF4/","section":"event","summary":"本篇文章是介绍信号检测模型(Macmillan and Creelman 2005; McNicol 2005)系列博文的第四部分。在第一部分中，我描述了如何使用贝叶斯(广义线性与非线性)建模技术估计单个被试的等方差高斯信号检测论(EVSDT)模型。在第二部分中，我介绍了如何使用层级贝叶斯模型同时估计多个被试的等方差高斯信号检测论(EVSDT)模型。而在第三部分，我展示了如何为单个被试的确信度评级(rating)数据建立等方差和不等方差信号检测论模型。然而，我们几乎总是希望讨论对样本总体的推论，而不是关注单个被试。进一步地讲，如果我们想要讨论单个被试，我们也应该把他们放在其他被试的情景中。在这里，我们提出一个多级(或称层级、混合)模型，通过包含样本总体和单个被试的参数来实现这些目标。我将再次使用基于R语言的brms包(Bürkner2017; RCore Team 2017)实现上述目的。我假设你已经熟悉先前系列文章中所介绍的内容，因此本篇文章相较于以前的文章更短。","tags":["OF"],"title":"翻译 | 信号检测论的贝叶斯估计 (四)","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":"原标题：Bayesian Estimation of Signal Detection Models, Part 3\n原文地址：https://vuorre.netlify.app/post/2017/10/12/bayesian-estimation-of-signal-detection-theory-models-part-3/\n原作者：Matti. Vuorre\n译者：刘帅呈 高昊\n校对：胡传鹏 金海洋 于玮烨\n引言 案例数据：评级任务 我们首先使用来自Decarlo（2003）的示例数据，简单地讨论一下评级任务。在之前的文章中，我们讨论了信号检测实验。这个实验中的实验材料要么是旧的，要么是新的，被试对实验材料进行 “旧”或“新”的二项的反应。在这里，我们将对实验任务进行简单的修改，被试将表达他们的（不）确定性：即在每个试次（trial）中呈现的实验材料依旧是旧的或者新的，但是被试需要对他们关于刺激材料的判断做出确信度评级。例如，在下面的数据中，参与者可以用数字来回答，表示他们认为这个项目是旧的确信度：1 =肯定是新的，…，6 =肯定是旧的。\n对于结果数据的一个解释是，被试为确信度评级设置了许多标准，例如：反应为6比反应为4需要更多的证据。也就是说，在回答“肯定是新的”、“可能是新的”等问题时，会有不同的标准。然而，被试的辨别力应该不受影响。\n下面的案例数据以一种汇总的形式呈现（整理了新或者旧（isold=1）两种试次类型中每个确信度的反应数量（Decarlo，2003））：\nlibrary(tidyverse) dsum \u0026lt;- tibble( isold = c(0,0,0,0,0,0,1,1,1,1,1,1), y =c(1:6, 1:6）, count = c(174, 172, 104, 92, 41, 8, 46, 57, 66, 101, 154, 173) ) dsum ## # A tibble: 12 x 3 ## isold y count ## \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 1 174 ## 2 0 2 172 ## 3 0 3 104 ## 4 0 4 92 ## 5 0 5 41 ## 6 0 6 8 ## 7 1 1 46 ## 8 1 2 57 ## 9 1 3 66 ## 10 1 4 101 ## 11 1 5 154 ## 12 1 6 173 然而，这几篇博客文章的一个主题是：我们不需要将数据汇总为计数数据（或单元（cell）数据，或类似的），而是尽可能的直接使用实验提供的原始数据。我认为，特别是当我们想包含协变量时，使用这种试次水平的数据在计算和概念上都更容易。以下是原始试次水平格式的数据：\nd \u0026lt;- tibble( isold = c(rep(0, 174), rep(0, 172), rep(0, 104), rep(0, 92), rep(0, 41), rep(0, 8), rep(1, 46), rep(1, 57), rep(1, 66), rep(1, 101), rep(1, 154), rep(1, 173)), y = c(rep(1, 174), rep(2, 172), rep(3, 104), rep(4, 92), rep(5, 41), rep(6, 8), rep(1, 46), rep(2, 57), rep(3, 66), rep(4, 101), rep(5, 154), rep(6, 173)) ) d ## # A tibble: 1,188 x 2 ## isold y ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0 1 ## 2 0 1 ## 3 0 1 ## 4 0 1 ## 5 0 1 ## 6 0 1 ## 7 0 1 ## 8 0 1 ## 9 0 1 ## 10 0 1 ## # ... with 1,178 more rows （上面的代码不够整洁，如果有人知道可以把汇总数据整理为整洁的试次水平数据的其他方法，请告诉我。）如果你想在自己的电脑上面尝试，可以在R语言上执行上述代码。我们现在可以从EVSDT模型开始，让信号检测论模型拟合这个被试的数据。\nEVSDT：一个被试的评级反应 回忆一下，二项反应的EVSDT模型中，我们对概率P（在试次i中是旧的反应）进行了建模：\n$$ p_i = Φ(d\u0026#39;\\text{isold}_i - C) $$ 该模型呈现了对新的实验材料反应为旧（c=zFAR）的概率（z分数），以及对旧的实验材料反应依然为旧（d\u0026#39;）的增量（z分数）。对于评级数据，模型是相似的，只是现在包含了多个c。这表示对不同确信度评级反应的不同标准。这些标准被认为是有顺序的——当试次中的信号（记忆强度）较弱时，与报告“确定为旧”相比，人们应该更容易报告“不确定为旧”。\n评级反应的EVSDT模型对反应确信度评级为k或更低（信心评级）的累计概率进行建模：\n$$ p(y_i \\ ≤ k_i) = Φ(d\u0026#39;\\text{isold}_i - C_{ki}) $$ 该模型也被称为序数概率Φ模型（Ordinal Probit Model），它可以通过很多回归模型软件进行拟合。Decarl（2003）展示了在SPSS中如何使用PLUM程序拟合单个被试的模型。然而，我们可以通过在R语言中brms工具包（Bürkner，2017; Stan Development Team，2016）估计这个模型并得到该模型的贝叶斯推论。使用该模型（暂时不考虑先验分布）对上述数据进行估计的brms语法如下:\nfit1 \u0026lt;- brm(y ~ isold, family = cumulative(link=\u0026#34;probit\u0026#34;), data = d, cores = 4, file = here::here(\u0026#34;static/data/sdtmodel3-1\u0026#34;)) 该模型估计了每个反应类别的截距（反应标准）和isold的效应，即d\u0026#39;。模型的后验分布总结如下：\nsummary(fit1) ## Family: cumulative ## Links: mu = probit; disc = identity ## Formula: y ~ isold ## Data: d (Number of observations: 1188) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept[1] -0.44 0.05 -0.54 -0.35 4256 1.00 ## Intercept[2] 0.23 0.05 0.14 0.33 5885 1.00 ## Intercept[3] 0.67 0.05 0.57 0.77 4736 1.00 ## Intercept[4] 1.20 0.06 1.09 1.31 4620 1.00 ## Intercept[5] 1.88 0.07 1.75 2.01 4436 1.00 ## isold 1.26 0.07 1.13 1.39 4157 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 5个截距是模型中的5个标准，isold为d\u0026#39;。我也用SPSS对这个模型进行了估计，比较这两种方法的结果可能会有帮助：\nPLUM y WITH x /CRITERIA=CIN(95) DELTA(0) LCONVERGE(0) MXITER(100) MXSTEP(5) PCONVERGE(1.0E-6) SINGULAR(1.0E-8) /LINK=PROBIT /PRINT=FIT KERNEL PARAMETER SUMMARY. Parameter Estimates |-----------------|--------|----------|-----------------------------------| | |Estimate|Std. Error|95% Confidence Interval | | | | |-----------------------|-----------| | | | |Lower Bound |Upper Bound| |---------|-------|--------|----------|-----------------------|-----------| |Threshold|[y = 1]|-.442 |.051 |-.541 |-.343 | | |-------|--------|----------|-----------------------|-----------| | |[y = 2]|.230 |.049 |.134 |.326 | | |-------|--------|----------|-----------------------|-----------| | |[y = 3]|.669 |.051 |.569 |.769 | | |-------|--------|----------|-----------------------|-----------| | |[y = 4]|1.198 |.056 |1.088 |1.308 | | |-------|--------|----------|-----------------------|-----------| | |[y = 5]|1.876 |.066 |1.747 |2.005 | |---------|-------|--------|----------|-----------------------|-----------| |Location |x |1.253 |.065 |1.125 |1.381 | |-------------------------------------------------------------------------| Link function: Probit. 不出所料，从brms得到的数值结果（后验均值和标准差，可信区间）与从SPSS中得到的频率论结果相匹配。\n现在我们可以用图形来说明估计的参数如何映射到信号检测论模型。d\u0026#39;是信号和噪音分布峰值之间的距离：表示被试分辨信号和噪音的能力。这5个截距是指对不同确信度评级的标准（z分数）。如果把z分数换算成比例（例如使用R语言中的pnorm()函数），他们测量的是在噪音分布下z分数左边的累积面积(模型图见图1)。\n图1:通过参数后验均值可视化的等方差高斯信号检测模型。这两个分布一个是噪音分布（虚线），一个是信号分布（实线）。竖直的点线是反应标准，d’是两个分布的峰值距离。 UVSDT：一个被试的评级反应 值得注意的是，上面的模型假设信号和噪音分布的方差相等。不等方差SDT模型（UVSDT）允许信号分布和噪音分布有不同的方差（噪音的标准差还是固定为1），并且当允许信号分布的标准差变化时，它始终大于1。\nUVSDT模型增加了一个参数(Decarlo，2003)来描述信号分布的标准差。我们可以把它作为一个比例参数包含在 …","date":1611964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611964800,"objectID":"b3b50dbd1acb9df11d6eaef9eef68912","permalink":"https://terryzang.github.io/event/opentransfer/2021%E8%B4%9D%E5%8F%B6%E6%96%AF3/","publishdate":"2021-01-30T00:00:00Z","relpermalink":"/event/opentransfer/2021%E8%B4%9D%E5%8F%B6%E6%96%AF3/","section":"event","summary":"这篇文章是信号检测模型系列的第三部分：在第一部分中，我主要讨论了如何使用贝叶斯（广义线性和非线性）建模技术估计单个被试的等方差高斯信号检测论（EVSDT）模型。在第二部分中，我主要讨论了如何使用层级贝叶斯模型同时估计多个被试的等方差高斯信号检测论模型。在这篇文章中，我扩展到了对评级（rating）任务的讨论，然后展示如何借助R语言和brms工具包（Burkner2017; R Core Team 2017）使用贝叶斯方法估计相等与不等方差高斯信号检测论（UVSDT）的模型。在这里，我们主要讨论单个被试的估计模型。在下一篇博客中，我们将讨论多被试的层级模型。","tags":["OF"],"title":"翻译 | 信号检测论的贝叶斯估计 (三)","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":"原标题：Bayesian Estimation of Signal Detection Models, Part 2\n原文地址：https://vuorre.netlify.app/post/2017/10/12/bayesian-estimation-of-signal-detection-theory-models-part-2/\n原作者：Matti. Vuorre\n译者：高昊 田宇浩\n校对：胡传鹏 金海洋 于玮烨\n引言 本篇博文承接第一部分。在第一部分中我们使用以下三种方法对一个被试的EVSDT模型的参数进行估计:\n- 手动计算点估计（Stanislaw and Todorov，1999）\n- 使用广义线性模型（GLM）来估计（DeCarlo，1998）\n- 使用brm非线性模型语法进行估计（Burkner，2017）\n但是，与参加实验的某些特定被试相比，研究者通常会对他们所代表的总体更感兴趣。因此，我们不会满足于那些恰巧参加了我们研究的被试的参数估计结果。最终统计模型的参数应该能描述研究者所感兴趣的总体的特征。\n一般来说，有两种方法可以得到总体水平的参数。目前而言，最流行的方法是对每个被试进行点估计，即手动计算d’和c的均值和标准差。基于该方式，我们可以计算标准误，t值，置信区间等。另外一种我想推广的方法是建立一个更广的，可以同时估计被试水平和总体水平参数的模型。我们称后面这种方法为“层级”（Hierarchical）或“多水平”（Multilevel）模型（Gelman and Hill，2007; Rouder and Lu，2005） 。\n在本篇博客中，我会使用R语言和brms 包来展示如何使用上述两种方法估计EVSDT模型中总体水平的参数（R Core Team 2017; Bürkner 2017）。\n示例数据 我们在本篇博客中将继续使用第一部分中使用的数据集。示例数据叫做confcontr，是以dataframe的格式存储的：“ 这些数据来自于Skagerberg和Wright关于记忆一致性研究的对照组。它使用的基本可以算是最简单的新旧再认记忆的实验设计”（Skagerberg and Wright 2008）。\n为了完整，我们重复呈现第一部分的一些代码，如下所示 library(tidyverse) library(sdtalt) data(confcontr) # We prefer working with \u0026#34;tibbles\u0026#34; over \u0026#34;data.frame\u0026#34;s confcontr \u0026lt;- as_tibble(confcontr) confcontr # Create a variable in data indicating if trial was hit/miss/etc. sdt \u0026lt;- confcontr %\u0026gt;% mutate(type = \u0026#34;hit\u0026#34;, type = ifelse(isold==1 \u0026amp; sayold==0, \u0026#34;miss\u0026#34;, type), type = ifelse(isold==0 \u0026amp; sayold==0, \u0026#34;cr\u0026#34;, type), # Correct rejection type = ifelse(isold==0 \u0026amp; sayold==1, \u0026#34;fa\u0026#34;, type)) # False alarm # Count hits/misses/etc. and format data to one row per person sdt \u0026lt;- sdt %\u0026gt;% group_by(subno, type) %\u0026gt;% summarise(count = n()) %\u0026gt;% spread(type, count) # Format data to one row per person # Calculate point estimates of EVSDT parameters sdt \u0026lt;- sdt %\u0026gt;% mutate(zhr = qnorm(hit / (hit+miss)), zfa = qnorm(fa / (fa+cr)), dprime = zhr-zfa, crit = -zfa) 总体水平EVSDT模型 我们现在通过手动计算和层级模型两种方法来估计这些数据总体水平的EVSDT模型的参数。对于多水平的模型，我提供了R和brms代码来估计广义线性混合模型（GLMM， Generalized Linear Mixed Model）的参数。我也会介绍如何用brm非线性语法来估计GLMM模型的参数，以此来帮助我们理解第三部分中所使用的不等方差模型。\n总基于整合被试点估计的参数估计体水平EVSDT模型 之前，我们计算了样本集合中每一个被试的d\u0026#39;和c subno cr fa hit miss zhr zfa dprime crit 53332025220.0801-0.3120.3930.312 54391428190.2423-0.6310.8730.631 55361731160.4113-0.4660.8770.466 5643103890.8724-0.8831.7550.883 57351829180.2977-0.4130.7110.413 因此我们可以计算这两个参数的样本均值和标准差。下面给出其中一种方式： sdt_sum \u0026lt;- select(sdt, subno, dprime, crit) %\u0026gt;% # Select these variables only gather(parameter, value, -subno) %\u0026gt;% # Convert data to long format group_by(parameter) %\u0026gt;% # Prepare to summarise on these grouping variables # Calculate summary statistics for grouping variables summarise(n=n(), mu=mean(value), sd=sd(value), se=sd/sqrt(n)) sdt_sum 样本均值（mu）是对群体均值的估计，样本标准差（sd）除以是对样本分布标准差的估计，也就是标准误差（se）。由于抽样分布的标准差是未知的，而且只能通过数据进行估计，因此，研究者几乎总是用t分布来代替高斯分布来获得p值和置信区间（也就是说，我们进行t检验，而不是z检验）。 在这里需要注意的是该方法涉及到对未知参数的点估计（被试水平（subject-specific）的参数），接着用额外的模型来整合这些参数。换而言之，我们首先拟合包含了P个参数的N个模型（这里N=被试数量，P=2个参数），紧接着再用P个模型来总结被试水平的参数。这包含了相当多的模型！ 下一步，我们将会使用层级回归方法一步获得被试水平和总体水平的参数。 基于层级模型的参数估计（GLMM） 我们可以使用EVSDT模型来估计每一位被试的参数，随后用广义线性混合模型（GLMM）进一步估计总体的均值。Gelman, Hill（2007）和McELreath（2016）对层级模型有很好且全面的介绍。Rouder和 Lu（2005） 和 Rouder等人（2007）在信号检测理论的框架下讨论了层级模型。 该模型与第一部分讨论的GLM十分相似，但是现在被试特有的d’和c是来自同一个多元正态分布。该模型中的“超参数（hyperparameter）”描述了总体水平的参数。我们用下标j描述被试j的参数，下标i描述数据的第 i 行，因此模型可以写成， $$ y_{ij} \\sim \\text{Bernoulli}(p_{ij})$$ $$ Phi(p_{ij}) = \\beta_{0j} + \\beta_{1j} \\text{isold}_{ij}$$ 当被试 j 在第 i 次试验（trial）上的反应是新的（“new!”），那么结果$y_{ij} = 0$；当被试j在第 i 次试验上的反应是旧的（“old!”），那么结果$y_{ij} = 1$. 第 j 个被试在第i次试验上的反应为旧的的概率记作$p_{ij}$。然后，我们针对$p_{ij}$概率（z分数；Φ，“Phi”）编写线性模型。\n被试水平的截距（回忆上一部分，$β_0 = -z\\text{FAR}$）和斜率（$β_1 = d\u0026#39;$）是由一个具有均值和协方差矩阵的多元正态分布来描述的。\n$$ \\begin{bmatrix} \\beta_{0j} \\\\ \\beta_{1j} \\end{bmatrix} \\sim N \\left( \\begin{bmatrix} \\mu_0 \\\\ \\mu_1 \\end{bmatrix}, \\Sigma \\right) $$ 平均值$μ_0$和$μ_1$是总体水平的参数，可以解释为所有人的平均参数（Bolger and laurenceau 2013）.协方差矩阵Σ包含了被试水平参数的（协）方差。但是我发现讨论标准差（我称之为τ）和相关会更加简单。标准差描述了总体中个体之间的异质性。相关描述了d’和c的协方差，即有更高d’的样本是否有更大可能性有更高的c?\n与运行多个独立的GLM相比，这个模型包含了更多的信息，因为它可以对协方差进行建模，并且有效回答了有关异质性（heterogeneity）的重要问题。\n这个模型的brms语法与单个被试的模型很像。我们需要估计5个总体水平的参数。截距和斜率描述的是均值：在R和brms模型语法中，截距恒等为1（可以省略，因为它是自动包含的，为清楚起见，这里将其包含在内），一个变量的斜率通过包含数据中的那个变量名称来表示。为了包含这两个回归系数，我们记为sayold ~ 1 + isold.\n但是，我们还需要估计三个（协）方差参数。为了包含被试水平的参数（回顾，在数据d中，被试被标记为subno)和（协）方差参数，我们可以扩展上述公式，表示为sayold ~ 1 + isold + (1 + isold | subno). 括号中的部分描述了被试subno指定的截距为1，斜率为isold。brm()调用的其他部分与第一部分相同。\nfitglmm \u0026lt;- brm(sayold ~ 1 + isold + (1 + isold | subno), family = bernoulli(link=\u0026#34;probit\u0026#34;), data = confcontr, cores = 4, file = here::here(\u0026#34;static/data/sdtmodel2-1\u0026#34;)) 接下来我们看一下GLMM估计的参数。首先，我们聚焦输出结果中的“总体水平效应（Population-Level Effects）”。这两个参数分别是平均判断标准c（截距Intercept，$μ_0$）和d\u0026#39;（斜率isold,$μ_1$)。我们正在查看的是参数后验分布（中随机抽取的样本）的数值综合情况: Estimate是后验平均值。\nsummary(fitglmm) ## Family: bernoulli ## Links: mu = probit ## Formula: sayold ~ 1 + isold + (1 + isold | subno) ## Data: confcontr (Number of observations: 3100) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Group-Level Effects: ## ~subno (Number of levels: 31) ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sd(Intercept) 0.26 0.06 0.16 0.39 1616 1.00 …","date":1611360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611360000,"objectID":"be73e32fb19dccd37d5882aac8bc468e","permalink":"https://terryzang.github.io/event/opentransfer/2021%E8%B4%9D%E5%8F%B6%E6%96%AF2/","publishdate":"2021-01-23T00:00:00Z","relpermalink":"/event/opentransfer/2021%E8%B4%9D%E5%8F%B6%E6%96%AF2/","section":"event","summary":"这是该系列四部曲的第二部分。我在第一部分阐述了如何在贝叶斯（广义线性和非线性）框架下使用等方差高斯信号检测模型（Equal Variance Gaussian SDT，EVSDT）对单个被试的数据进行估计。第三部分，我会阐述如何在非线性贝叶斯框架下去估计不等方差的高斯信号检测模型。在这里，我将会介绍如何使用贝叶斯广义层级模型同时对多个被试EVSDT模型的参数进行估计。我也会在本篇博客中介绍如何在R中实现上述分析。","tags":["OF"],"title":"翻译 | 信号检测论的贝叶斯估计 (二)","type":"event"},{"authors":["OpenTransfer Team"],"categories":null,"content":"原标题：Bayesian Estimation of Signal Detection Models, Part 1\n原文地址：https://vuorre.netlify.app/post/2017/10/09/bayesian-estimation-of-signal-detection-theory-models-part-1/\n原作者：Matti. Vuorre\n译者：王倩 王齐飞 张译文\n校对：胡传鹏 金海洋 姚佳宇\n引言 假如我们在进行一项再认实验，这个实验向被试呈现了一组图片，这些图片中有些是新的（被试之前没有见过的），而有些是旧的（被试之前已看过的）。被试需要对呈现的每一张图片进行反应：“新（未见过）”或者“旧（见过）”。SDT通过分别测量被试的敏感性以及判断标准（一种对反应偏向(response bias)测量）来建立每个被试再认过程的模型。SDT模型的基本理念是：在每个试次中，当刺激呈现时，被试心里会产生一种“熟悉”（或者记忆强度）的信号。随后被试会依据这些信号，判断当前的刺激是“新”或“旧”。Macmillan 和 Creelman（2005）一书中对SDT有更加详细的介绍。\n信号检测理论 假如我们在进行一项再认实验，这个实验向被试呈现了一组图片，这些图片中有些是新的（被试之前没有见过的），而有些是旧的（被试之前已看过的）。被试需要对呈现的每一张图片进行反应：“新（未见过）”或者“旧（见过）”。SDT通过分别测量被试的敏感性以及判断标准（一种对反应偏向(response bias)测量）来建立每个被试再认过程的模型。SDT模型的基本理念是：在每个试次中，当刺激呈现时，被试心里会产生一种“熟悉”（或者记忆强度）的信号。随后被试会依据这些信号，判断当前的刺激是“新”或“旧”。Macmillan 和 Creelman（2005）一书中对SDT有更加详细的介绍。\n案例数据 接下来我们将用R统计编程语言来探究一个实例，首先我们需要加载tidyverse工具包（Wickham，2016）\nlibrary(tidyverse) 我们将使用stdalt包中的案例数据（Wright，2011）。该包以前可以在CRAN上找到，但现在已经没有了，因此必须从GitHub安装： devtools::install_github(\u0026#34;cran/sdtalt\u0026#34;) 这个案例数据称为“confcontr”，数据来自Skagerberg和Wright记忆一致性(memory conformity)研究中的对照组(Skagerberg \u0026amp; Wright，2008) # install.packages(\u0026#34;sdtalt\u0026#34;) library(sdtalt) data(confcontr) ## # A tibble: 3,100 x 3 ## subno sayold isold ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 53 1 0 ## 2 53 1 1 ## 3 53 1 1 ## 4 53 1 1 ## 5 53 1 0 ## 6 53 1 1 ## 7 53 1 0 ## 8 53 0 0 ## 9 53 0 1 ## 10 53 0 1 ## # ... with 3,090 more rows 在这篇文章中，我们将利用这些数据来估算该数据包中的某个被试在等方差SDT模型下的参数d’ （辨别力指标/感觉敏感性指标）和 c（报告标准）。\n等方差高斯SDT模型 首先我们讨论最常见的SDT模型，即假定被试对两种信号的熟悉程度的分布属于高斯分布（即正态分布），且这两个分布的方差是齐性的，但均值可能不同（例如，对旧刺激的熟悉程度更高）。该模型就称为EVSDT (Equal Variance Gaussian SDT Model) 模型。我们用三种方法来估算单个被试的模型：\n1. 依据计算公式，使用R进行“手动”点估计运算；\n2. 使用贝叶斯广义线性模型（GLM；Generalized linear models）来进行估算；\n3. 使用贝叶斯非线性模型来进行估算。\nEVSDT参数的点估计 首先，我们分别对数据包中每一位被试的EVSDT参数进行最大似然估计。在此之前，我注意到只有在手动点估计运算时才需要进行这种数据处理，因此接下来所介绍的建模方法，都将采用原始数据，以略去繁琐的步骤。首先，我们将计算被试每个试次的反应（击中(hit)、虚报(false alarm)、正确拒斥(correct rejection)、漏报(miss)）并将其放到新变量type中：\nsdt \u0026lt;- confcontr %\u0026gt;% mutate(type = \u0026#34;hit\u0026#34;, type = ifelse(isold==1 \u0026amp; sayold==0, \u0026#34;miss\u0026#34;, type), type = ifelse(isold==0 \u0026amp; sayold==0, \u0026#34;cr\u0026#34;, type), # Correct rejection type = ifelse(isold==0 \u0026amp; sayold==1, \u0026#34;fa\u0026#34;, type)) # False alarm 然后我们可以统计某个被试这四种反应类型的数量，最后将每个被试的反应情况放在同一行上。 sdt \u0026lt;- sdt %\u0026gt;% group_by(subno, type) %\u0026gt;% summarise(count = n()) %\u0026gt;% spread(type, count) # Format data to one row per person 对于单个被试，d’ 可由标准化后的击中率和虚报率(hit and false alarm rates)之差计算得来(Stanislaw \u0026amp; Todorov，1999)。 Φ 是累积正态密度函数(cumulative normal density function)，可将z分数转换为概率，其反函数Φ^(-1) 将概率（例如击中率或虚报率）转换为z分数。标准化后的击中率和虚报率分别表示为 zHR 和zFAR。反应标准c则由-zFAR（负虚报率的标准分数）表示(DeCarlo，1998)。\n我们可以用qnorm()进行z分数转化（即Φ^(-1)）。接下来，根据每个被试反应类型（击中，虚报，漏报，正确拒斥）的数量计算出d’ 和c ： sdt \u0026lt;- sdt %\u0026gt;% mutate(zhr = qnorm(hit / (hit+miss)), zfa = qnorm(fa / (fa+cr)), dprime = zhr-zfa, crit = -zfa) round(sdt, 2) ## # A tibble: 31 x 9 ## # Groups: subno [31] ## subno cr fa hit miss zhr zfa dprime crit ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 53 33 20 25 22 0.08 -0.31 0.39 0.31 ## 2 54 39 14 28 19 0.24 -0.63 0.87 0.63 ## 3 55 36 17 31 16 0.41 -0.47 0.88 0.47 ## 4 56 43 10 38 9 0.87 -0.88 1.76 0.88 ## 5 57 35 18 29 18 0.3 -0.41 0.71 0.41 ## 6 58 41 12 30 17 0.35 -0.75 1.1 0.75 ## 7 59 46 7 21 26 -0.13 -1.12 0.98 1.12 ## 8 60 38 15 33 14 0.53 -0.570 1.1 0.570 ## 9 61 42 11 25 22 0.08 -0.81 0.9 0.81 ## 10 62 45 8 22 25 -0.08 -1.03 0.95 1.03 ## # ... with 21 more rows 现在，我们根据这些数据就得到了每个被试d’ 和c的点估计， 53号被试的潜在EVSDT模型如图一所示: 使用GLM估算EVSDT模型 广义线性模型是一类功能强大的回归模型，可以对二项反应进行建模，例如前文所提到的对“新”或“旧”的反应。在confcontr中，每个试次都有一种回答，“旧”(sayold = 1) 或者 “新” (sayold = 0)；我们用GLM对刺激类型的反应进行回归：需要判断的刺激（图片）可能是新的(isold = 0)也可能是旧的(isold = 1)。在二项反应的GLM中，我们假定反应属于贝努里（Bernoulli）分布（即只有一个试次的二项分布），且其概率$p_i$为$y_i=1$ 由于我们希望使用线性模型（广义线性模型）对概率p进行估计，但概率p本身有上限和下限（分别为1和0），因此，我们不用线性模型直接对p进行建模。相反，我们用一个连结函数将p转化为‘线性预测值’ η，并用线性回归模型对 η建模。如果该连结函数是一个概率(probit)，那我们就得到了一个‘probit GLM’。 如前所述，Φ是一个累积正态密度函数并能将z 值转化为概率，那我们可以用一个截距和斜率来表示η。 在这一参数化过程中，模型的截距是标准化的虚报率（当η为0时报告1的概率），我们将其作为标准，用c表示。模型的斜率是由z分数所表示的击中率（当η为1时报告1）相对于截距（即标准化的虚报率）的提升，这是d’的另一种表达形式。因此， DeCarlo (1998)已详细地探讨了SDT模型与GLM的关系。从GLM框架来考虑SDT模型的两个直接好处是，可以容易得到c和d\u0026#39;两个预测值以及可用层级模型来估计包含各种相关系数的SDT模型(DeCarlo,2010; Rouder \u0026amp; Lu, 2005)。第二点意味着多个被试（和项目）可同时用该模型进行拟合。我们将在第二部分中讨论这一点。\n因为我们把SDT写成了一个GLM模型，我们有多种多样的软件可以对这个模型进行估计。这里我们使用贝叶斯回归模型R语言工具包brms (Bürkner 2017; Stan Development Team 2016)，因为其模型公式的语法可以很好地用于我们之后要探讨的更复杂的模型。 通过输入一个在brms语法下的模型公式，一个用连结函数处理过的反应分布以及一个数据框架（data frame）作为参数(arguments)，我们就可以用brms的brm()函数来估计GLM。brms的模型语法用了数据中的变量名。我们用公式sayold ~ isold来回归二元预测值isold 的二项反应sayold。 接下来需要输入参数，即反应分布，用参数family表示，我们用 family = bernoulli(link=\u0026#34;probit\u0026#34;)这一语法来表示有概率连结函数的贝努里分布。这里我们只需要第一个被试的数据(subno 53)，因此，用data = filter(confcontr, subno==53)来表示该数据。 brm()函数也允许设定参数的先验分布，但这个模型中我们略去对先验的讨论。最后，我们将参数cores设置为4以运行多个马氏链（chains；这能使模型估计得更快）。根据以上的设置，我们可以把SDT作为一个probit GLM进行估计。估计confcontr数据中53号被试SDT模型的具体函数如下：\nlibrary(brms) glmfit \u0026lt;- brm(sayold ~ isold, family = bernoulli(link=\u0026#34;probit\u0026#34;), data = filter(confcontr, subno==53), cores = 4, file = here::here(\u0026#34;static/data/sdtmodel1-1\u0026#34;)) 估计的模型储存于glmfit中， summary()可以输出估计的参数值。 summary(glmfit) ## Family: bernoulli ## Links: mu = …","date":1608076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608076800,"objectID":"b6dd490b7eba56a6105714e6550268d3","permalink":"https://terryzang.github.io/event/opentransfer/2020%E8%B4%9D%E5%8F%B6%E6%96%AF1/","publishdate":"2020-12-16T00:00:00Z","relpermalink":"/event/opentransfer/2020%E8%B4%9D%E5%8F%B6%E6%96%AF1/","section":"event","summary":"这篇文章是三篇博文系列中的第一部分（译者注：该系列一共有四篇文章。在这篇文章中，作者将介绍如何使用不同的方法来估计单个被试的信号检测论的参数）。在第二部分，我将描述如何使用层级贝叶斯模型同时为多个被试估算等方差高斯SDT（Signal Detection Theory）模型。在第三部分，我将介绍如何使用一个贝叶斯非线性分层模型来估计非等方差的高斯SDT模型。","tags":["OF"],"title":"翻译 | 信号检测论的贝叶斯估计 (一)","type":"event"}]